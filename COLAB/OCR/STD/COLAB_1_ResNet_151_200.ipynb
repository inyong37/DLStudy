{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d3WhoYlxxc67",
    "colab_type": "code",
    "outputId": "df319574-e576-47ce-b4d0-ce3e671a7da9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560590674015E12,
     "user_tz": -540.0,
     "elapsed": 39645.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Inyong Hwang (lkan6004@gmail.com)\n",
    "# Date: 2019-06-16-Sun\n",
    "# Korean Character STR 64*64 by ResNet epoch=151~200 \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SdC6ExhCxkKN",
    "colab_type": "code",
    "outputId": "c8c4c24e-2502-4505-9a89-5faf0f740751",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560590682122E12,
     "user_tz": -540.0,
     "elapsed": 4703.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Google Drive=====\n",
      " 논문\t\t\t      'Colab Notebooks'   Lab-Desktop   PUBLIC\n",
      "'AI 사물인식 해커톤 (2).zip'   Dataset\t\t  Program       USB\n",
      "=====input=====\n",
      "images.pkl  labels.pkl\n"
     ]
    }
   ],
   "source": [
    "print('=====Google Drive=====')\n",
    "!ls '/content/drive/My Drive/'\n",
    "print('=====input=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zajE3nISxsQA",
    "colab_type": "code",
    "outputId": "327192b9-374a-437e-b7ca-0719f533fdc3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560610126711E12,
     "user_tz": -540.0,
     "elapsed": 4055514.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12699.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels.pkl\n",
      "loaded!\n",
      "loading images.pkl\n",
      "loaded!\n",
      "# of images: 139104\n",
      "Shape of images: (64, 64, 1)\n",
      "# of train set: 111283 # of test set: 27821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0615 09:25:19.354409 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0615 09:25:19.441110 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0615 09:25:19.492045 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0615 09:25:19.493100 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0615 09:25:19.494237 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0615 09:25:22.324966 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0615 09:25:27.427431 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0615 09:25:34.455775 140067593578368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Image (InputLayer)        (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   160         Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 16)   1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 16)   1040        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 16)   2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   1088        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   1040        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   1088        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 16)   1040        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 16)   2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 16)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   1088        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   4160        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 128)  8320        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 128)  8320        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 128)  0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   8256        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  8320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   8256        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 128)  8320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 128)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 64)   8256        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 128)  8320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 64)   8256        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 128)  8320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 64)   8256        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 128)  8320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 128)  16512       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 128)  147584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 128)  512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 256)  33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 256)  33024       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 256)  0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  32896       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 128)  512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 256)  33024       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 256)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 256)  1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 128)  32896       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 128)  147584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 256)  33024       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 256)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 256)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 128)  32896       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 128)  147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 128)  512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 256)  33024       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 256)  0           add_15[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 256)  1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 256)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 128)  32896       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 256)  33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 256)  0           add_16[0][0]                     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 256)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 128)  32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 128)  147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 128)  512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 256)  33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 256)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 2, 256)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1008)         1033200     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,704,080\n",
      "Trainable params: 2,693,680\n",
      "Non-trainable params: 10,400\n",
      "__________________________________________________________________________________________________\n",
      "Learning rate:  0.001\n",
      "ResNet56v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 09:25:35.305230 140067593578368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89026 samples, validate on 22257 samples\n",
      "Epoch 151/200\n",
      "Learning rate:  1e-05\n",
      " - 403s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00151: val_acc improved from -inf to 0.99483, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_151_200/checkpoint.151.hg\n",
      "Epoch 152/200\n",
      "Learning rate:  1e-05\n",
      " - 385s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.99483 to 0.99519, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_151_200/checkpoint.152.hg\n",
      "Epoch 153/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.99519 to 0.99524, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_151_200/checkpoint.153.hg\n",
      "Epoch 154/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.99524\n",
      "Epoch 155/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.99524\n",
      "Epoch 156/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.99524\n",
      "Epoch 157/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.99524\n",
      "Epoch 158/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.99524\n",
      "Epoch 159/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.99524\n",
      "Epoch 160/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.99524\n",
      "Epoch 161/200\n",
      "Learning rate:  1e-05\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.99524\n",
      "Epoch 162/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.99524\n",
      "Epoch 163/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.99524\n",
      "Epoch 164/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.99524\n",
      "Epoch 165/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.99524\n",
      "Epoch 166/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.99524\n",
      "Epoch 167/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.99524\n",
      "Epoch 168/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.99524\n",
      "Epoch 169/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.99524\n",
      "Epoch 170/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.99524\n",
      "Epoch 171/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.99524\n",
      "Epoch 172/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.99524\n",
      "Epoch 173/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.99524\n",
      "Epoch 174/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.99524\n",
      "Epoch 175/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.99524\n",
      "Epoch 176/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.99524\n",
      "Epoch 177/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.99524\n",
      "Epoch 178/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.99524\n",
      "Epoch 179/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.99524\n",
      "Epoch 180/200\n",
      "Learning rate:  1e-06\n",
      " - 386s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.99524\n",
      "Epoch 181/200\n",
      "Learning rate:  1e-06\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.99524\n",
      "Epoch 182/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.99524\n",
      "Epoch 183/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.99524\n",
      "Epoch 184/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.99524\n",
      "Epoch 185/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.99524\n",
      "Epoch 186/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.99524\n",
      "Epoch 187/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.99524\n",
      "Epoch 188/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.99524\n",
      "Epoch 189/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.99524\n",
      "Epoch 190/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.99524\n",
      "Epoch 191/200\n",
      "Learning rate:  5e-07\n",
      " - 385s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.99524\n",
      "Epoch 192/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.99524\n",
      "Epoch 193/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.99524\n",
      "Epoch 194/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.99524\n",
      "Epoch 195/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.99524\n",
      "Epoch 196/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.99524\n",
      "Epoch 197/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.99524\n",
      "Epoch 198/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.99524\n",
      "Epoch 199/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.99524\n",
      "Epoch 200/200\n",
      "Learning rate:  5e-07\n",
      " - 386s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.99524\n",
      "Model:  resnet56v2_151_200 , Loss:  0.03939264086218486 , Accuracy:  0.9945365012041264\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6JL1SJ5cqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read directory\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'resnet56v2_151_200'\n",
    "input_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'\n",
    "output_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/'\n",
    "json_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/model.json'\n",
    "weights_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/weights.h5'\n",
    "\n",
    "if os.path.isdir(output_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "if os.path.isdir(output_dir + str(model_name)):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir + str(model_name))\n",
    "   \n",
    "filenames = os.listdir(input_dir)\n",
    "for filename in filenames:\n",
    "    if 'image' in filename:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        print('loaded!')\n",
    "    else:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "        print('loaded!')\n",
    "\n",
    "X = np.array(X)\n",
    "X = X[:, :, :, np.newaxis]\n",
    "input_shape = X.shape[1:]\n",
    "Y = np.array(Y)\n",
    "num_classes = len(Counter(Y))\n",
    "Y = to_categorical(Y, num_classes)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=37, shuffle=True)\n",
    "print('# of images: %d' % len(X))\n",
    "print('Shape of images:', X.shape[1:])\n",
    "print('# of train set: %d' % len(X_train), '# of test set: %d' % len(X_test))\n",
    "del X, Y\n",
    "\n",
    "# Define \n",
    "\n",
    "version = 2\n",
    "n = 6\n",
    "depth = n * 9 + 2\n",
    "batch_size = 128\n",
    "epochs = 200 # 200\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "json_file = open(json_dir, 'r')\n",
    "json_model = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(json_model)\n",
    "model.load_weights(weights_dir)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n",
    "print(model_type)\n",
    "checkpoint = ModelCheckpoint(filepath=output_dir + str(model_name) + '/checkpoint.{epoch:03d}.hg',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=2,\n",
    "                             save_best_only=True)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "fit = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=callbacks, validation_split=0.2, initial_epoch=150)\n",
    "eva = model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "\n",
    "def plot_loss(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_loss = plt\n",
    "    plt_loss.plot(history.history['loss'])\n",
    "    plt_loss.plot(history.history['val_loss'])\n",
    "    plt_loss.title('Model Loss')\n",
    "    plt_loss.xlabel('Epoch')\n",
    "    plt_loss.ylabel('Loss')\n",
    "    plt_loss.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/loss.png'\n",
    "    plt_loss.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def plot_acc(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_acc = plt\n",
    "    plt_acc.plot(history.history['acc'])\n",
    "    plt_acc.plot(history.history['val_acc'])\n",
    "    plt_acc.title('Model Accuracy')\n",
    "    plt_acc.xlabel('Epoch')\n",
    "    plt_acc.ylabel('Accuracy')\n",
    "    plt_acc.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/accuracy.png'\n",
    "    plt_acc.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def csv_fit(history, output_dir, model_name):\n",
    "    train_data = pd.DataFrame(history.history)\n",
    "    train_data.to_csv(output_dir + str(model_name) + '/csv_fit.csv')\n",
    "    return None\n",
    "\n",
    "\n",
    "def csv_eva(history, output_dir, model_name):\n",
    "    test_data = pd.DataFrame(history)\n",
    "    test_data = test_data.T\n",
    "    if len(history) == 5:\n",
    "        test_data_header = ['test_loss', 'test_acc', 'precision', 'recall', 'f1score']\n",
    "    else:\n",
    "        test_data_header = ['test_loss', 'test_acc']\n",
    "    test_data.to_csv(output_dir + str(model_name) + '/csv_eva.csv', header=test_data_header)\n",
    "    return None\n",
    "\n",
    "\n",
    "print('Model: ', model_name, ', Loss: ', eva[0], ', Accuracy: ', eva[1])\n",
    "plot_loss(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "plot_acc(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_fit(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_eva(history=eva, output_dir=output_dir, model_name=model_name)\n",
    "model.save(output_dir + str(model_name) + '/model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(output_dir + str(model_name) + '/model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "model_yaml = model.to_yaml()\n",
    "with open(output_dir + str(model_name) + '/model.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    yaml_file.close()\n",
    "model.save_weights(output_dir + str(model_name) + '/weights.h5')\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P03jIzPmZt7x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print('=====output=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_2/resnet56v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tlTPcCPG-lDX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COLAB_1_ResNet_151_200.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "13-lxwu3qrotHXNoOJYlVQmXFiK1QF67H",
     "timestamp": 1.560590481871E12
    },
    {
     "file_id": "1Oznv-mZazv25aXZjXV6vfb0xphxR2C7o",
     "timestamp": 1.560564439854E12
    },
    {
     "file_id": "1HdIYR8Sf10if8VmuF34CNP5ArUQJ0-Zs",
     "timestamp": 1.560534966683E12
    },
    {
     "file_id": "1A6BwnddGlmqiw9_7RNdf3lbwQhlJVGGw",
     "timestamp": 1.560508194285E12
    },
    {
     "file_id": "1iae9TyBzO1_n98a9eM4PRFBMSk7Obqg0",
     "timestamp": 1.560497983028E12
    },
    {
     "file_id": "1YFhVY6ZVnKuvtjN7A8vFhi_Gq-wuHNO5",
     "timestamp": 1.560493355521E12
    },
    {
     "file_id": "1oUBaAuby6umdZMtWxu5UTCkCihieEzko",
     "timestamp": 1.560479353623E12
    },
    {
     "file_id": "1OkE8SHoHTgYWYBgfaFvcyFHZyUhN4zOJ",
     "timestamp": 1.560308126915E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
