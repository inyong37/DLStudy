{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d3WhoYlxxc67",
    "colab_type": "code",
    "outputId": "21f1d2cb-c786-404c-a3bf-98e1ed987f8e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560535113179E12,
     "user_tz": -540.0,
     "elapsed": 29108.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Inyong Hwang (lkan6004@gmail.com)\n",
    "# Date: 2019-06-15-Sat\n",
    "# Korean Character STR 64*64 by ResNet epoch=51~100 \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SdC6ExhCxkKN",
    "colab_type": "code",
    "outputId": "92e2352d-5fba-4eb2-adc9-3617f9480497",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560535122638E12,
     "user_tz": -540.0,
     "elapsed": 4081.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Google Drive=====\n",
      " 논문\t\t\t      'Colab Notebooks'   Lab-Desktop   PUBLIC\n",
      "'AI 사물인식 해커톤 (2).zip'   Dataset\t\t  Program       USB\n",
      "=====input=====\n",
      "images.pkl  labels.pkl\n"
     ]
    }
   ],
   "source": [
    "print('=====Google Drive=====')\n",
    "!ls '/content/drive/My Drive/'\n",
    "print('=====input=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zajE3nISxsQA",
    "colab_type": "code",
    "outputId": "31b61457-6b03-4f05-f615-b93d1cc9bb70",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560554891581E12,
     "user_tz": -540.0,
     "elapsed": 1.9767024E7,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12699.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels.pkl\n",
      "loaded!\n",
      "loading images.pkl\n",
      "loaded!\n",
      "# of images: 139104\n",
      "Shape of images: (64, 64, 1)\n",
      "# of train set: 111283 # of test set: 27821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0614 17:59:12.877913 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0614 17:59:12.969707 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0614 17:59:13.024945 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0614 17:59:13.026259 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0614 17:59:13.027183 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0614 17:59:16.118493 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0614 17:59:21.405426 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0614 17:59:27.568804 139855377135488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Image (InputLayer)        (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   160         Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 16)   1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 16)   1040        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 16)   2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   1088        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   1040        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   1088        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 16)   1040        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 16)   2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 16)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   1088        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   4160        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 128)  8320        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 128)  8320        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 128)  0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   8256        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  8320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   8256        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 128)  8320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 128)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 64)   8256        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 128)  8320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 64)   8256        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 128)  8320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 64)   8256        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 128)  8320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 128)  16512       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 128)  147584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 128)  512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 256)  33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 256)  33024       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 256)  0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  32896       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 128)  512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 256)  33024       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 256)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 256)  1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 128)  32896       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 128)  147584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 256)  33024       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 256)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 256)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 128)  32896       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 128)  147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 128)  512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 256)  33024       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 256)  0           add_15[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 256)  1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 256)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 128)  32896       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 256)  33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 256)  0           add_16[0][0]                     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 256)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 128)  32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 128)  147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 128)  512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 256)  33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 256)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 2, 256)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1008)         1033200     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,704,080\n",
      "Trainable params: 2,693,680\n",
      "Non-trainable params: 10,400\n",
      "__________________________________________________________________________________________________\n",
      "Learning rate:  0.001\n",
      "ResNet56v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0614 17:59:28.468161 139855377135488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89026 samples, validate on 22257 samples\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      " - 408s - loss: 0.0493 - acc: 0.9964 - val_loss: 0.0810 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00051: val_acc improved from -inf to 0.98976, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.051.hg\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      " - 395s - loss: 0.0482 - acc: 0.9967 - val_loss: 0.1074 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.98976\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0490 - acc: 0.9964 - val_loss: 0.0994 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.98976\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0475 - acc: 0.9968 - val_loss: 0.0969 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.98976\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0461 - acc: 0.9968 - val_loss: 0.2665 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.98976\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0499 - acc: 0.9960 - val_loss: 0.8602 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.98976\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0419 - acc: 0.9977 - val_loss: 0.1413 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.98976\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0485 - acc: 0.9964 - val_loss: 0.0771 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.98976 to 0.99039, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.058.hg\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0455 - acc: 0.9967 - val_loss: 0.1155 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.99039\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0409 - acc: 0.9977 - val_loss: 0.3143 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.99039\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0462 - acc: 0.9967 - val_loss: 0.0602 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.99039 to 0.99434, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.061.hg\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      " - 394s - loss: 0.0417 - acc: 0.9969 - val_loss: 0.9848 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.99434\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0439 - acc: 0.9968 - val_loss: 0.1123 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.99434\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0444 - acc: 0.9966 - val_loss: 0.0738 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.99434\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0334 - acc: 0.9990 - val_loss: 0.0863 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.99434\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0462 - acc: 0.9954 - val_loss: 0.1007 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.99434\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0400 - acc: 0.9975 - val_loss: 0.0668 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.99434\n",
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0410 - acc: 0.9968 - val_loss: 0.0866 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.99434\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0347 - acc: 0.9982 - val_loss: 1.3816 - val_acc: 0.7698\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.99434\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0437 - acc: 0.9961 - val_loss: 0.1140 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.99434\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0392 - acc: 0.9975 - val_loss: 0.1072 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.99434\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0373 - acc: 0.9972 - val_loss: 0.1987 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.99434\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0384 - acc: 0.9972 - val_loss: 0.0687 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.99434\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0374 - acc: 0.9972 - val_loss: 0.0822 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.99434\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      " - 393s - loss: 0.0401 - acc: 0.9966 - val_loss: 0.1778 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.99434\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0343 - acc: 0.9981 - val_loss: 0.0940 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.99434\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0328 - acc: 0.9981 - val_loss: 0.1232 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.99434\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0412 - acc: 0.9960 - val_loss: 0.0616 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.99434\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0334 - acc: 0.9981 - val_loss: 0.1051 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.99434\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0377 - acc: 0.9970 - val_loss: 0.1242 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.99434\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      " - 392s - loss: 0.0371 - acc: 0.9973 - val_loss: 0.1691 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.99434\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      " - 392s - loss: 0.0301 - acc: 0.9991 - val_loss: 0.0552 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.99434\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      " - 392s - loss: 0.0276 - acc: 0.9997 - val_loss: 0.0534 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.99434 to 0.99443, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.083.hg\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      " - 392s - loss: 0.0264 - acc: 0.9997 - val_loss: 0.0516 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.99443 to 0.99483, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.084.hg\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      " - 392s - loss: 0.0250 - acc: 0.9997 - val_loss: 0.0501 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.99483\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0234 - acc: 0.9997 - val_loss: 0.0483 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.99483\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0215 - acc: 0.9997 - val_loss: 0.0472 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.99483\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0195 - acc: 0.9997 - val_loss: 0.0464 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.99483\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0174 - acc: 0.9997 - val_loss: 0.0445 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.99483\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0155 - acc: 0.9997 - val_loss: 0.0465 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.99483\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0138 - acc: 0.9997 - val_loss: 0.0410 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.99483\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0121 - acc: 0.9998 - val_loss: 0.0398 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.99483 to 0.99497, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.092.hg\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0115 - acc: 0.9996 - val_loss: 0.0415 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.99497\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0109 - acc: 0.9998 - val_loss: 0.0355 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.99497 to 0.99537, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/checkpoint.094.hg\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0101 - acc: 0.9998 - val_loss: 0.0358 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.99537\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      " - 390s - loss: 0.0095 - acc: 0.9998 - val_loss: 0.0368 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.99537\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      " - 390s - loss: 0.0091 - acc: 0.9997 - val_loss: 0.0372 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.99537\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0088 - acc: 0.9998 - val_loss: 0.0431 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.99537\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      " - 390s - loss: 0.0086 - acc: 0.9997 - val_loss: 0.0363 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.99537\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      " - 390s - loss: 0.0080 - acc: 0.9999 - val_loss: 0.0370 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.99537\n",
      "Model:  resnet56v2_51_100 , Loss:  0.04056084302766297 , Accuracy:  0.99442866899105\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXmcXGWV97+nll6T7s7SWTs7MSEE\nSEJEEJSA7CgoyACKIKK8jILo6LjMMKK4oI6voyyvCBIEVBgEwaggRkwQJSwhJEASQkL2vdNZe62u\nruf947m3u7q6qutWd91aus/386nPrbtVPbeX+7tnec4RYwyKoiiK0huBfA9AURRFKXxULBRFUZS0\nqFgoiqIoaVGxUBRFUdKiYqEoiqKkRcVCURRFSYuKhTKoEZHJImJEJOTh2E+KyD9yMS5FKTRULJSi\nQUQ2i0hEREYmbH/NueFPzs/Iuo1liIg0isjT+R6LomQTFQul2NgEXOGuiMixQEX+htODS4A24CwR\nGZPLL/ZiHSlKX1GxUIqNh4Cr4tavBh6MP0BEqkXkQRGpF5EtInKziAScfUER+ZGI7BORjcAFSc69\nT0R2icgOEfmOiAQzGN/VwN3A68CVCZ89QUR+54yrQUTujNv3GRFZKyJHRGSNiMxzthsROSruuF+K\nyHec9wtEZLuIfFVEdgP3i8gwEfmj8x0HnPd1cecPF5H7RWSns/9JZ/ubIvKhuOPCzs9obgbXrgxg\nVCyUYuNFoEpEjnZu4pcDv0o45g6gGpgKnIYVl2ucfZ8BPgjMBeYDH00495dAFDjKOeZs4NNeBiYi\nk4AFwK+d11Vx+4LAH4EtwGRgPPCIs+9S4JvO8VXAhUCDl+8ExgDDgUnAddj/6fud9YlAC3Bn3PEP\nYS2xY4BRwP842x+ku7idD+wyxrzmcRzKQMcYoy99FcUL2AycCdwM3AacCywGQoDB3oSDQASYFXfe\n/wGWOu//Blwft+9s59wQMBrrQiqP238FsMR5/0ngH72M72ZgpfN+PNABzHXWTwbqgVCS854Bbkrx\nmQY4Km79l8B3nPcLnGst62VMc4ADzvuxQAwYluS4ccARoMpZfwz4Sr5/5/oqnJf6OJVi5CHg78AU\nElxQwEggjH2Cd9mCvXmDvSluS9jnMsk5d5eIuNsCCcf3xlXAvQDGmB0i8hzWLfUaMAHYYoyJJjlv\nAvCOx+9IpN4Y0+quiEgF1lo4FxjmbB7qWDYTgP3GmAOJH2KM2Ski/wQuEZEngPOAm/o4JmUAom4o\npegwxmzBBrrPB36XsHsf0I698btMBHY473dhb5rx+1y2YS2LkcaYGudVZYw5Jt2YROS9wHTg6yKy\n24khvAf4mBN43gZMTBGE3gZMS/HRzXQP4CcGzRPLRn8JmAG8xxhTBbzfHaLzPcNFpCbFdz2AdUVd\nCiwzxuxIcZwyCFGxUIqVa4EzjDFN8RuNMR3Ao8B3RWSoE0f4N7riGo8CnxeROhEZBnwt7txdwF+A\n/ysiVSISEJFpInKah/FcjXWJzcK6fuYAs4Fy7FP6y1ih+r6IVIpImYic4pz7C+DLInKCWI5yxg2w\nEis4QRE5FxuD6Y2h2DjFQREZDtyScH1PA//PCYSHReT9cec+CczDWhSJFpsyyFGxUIoSY8w7xpjl\nKXbfCDQBG4F/AL8BFjr77sXGCFYBK+hpmVwFlABrgANY3/3Y3sYiImXAvwB3GGN2x702YV1mVzsi\n9iFs4HwrsB24zLmW3wLfdcZ5BHvTHu58/E3OeQeBjzv7euMnWIHah00G+HPC/k9gLa+3gL3AF9wd\nxpgW4HGsey/x56IMcsQYbX6kKIpFRL4BvMsYc2Xag5VBhQa4FUUB7BwMrHvvE/kei1J4qBtKURRE\n5DPYAPjTxpi/53s8SuGhbihFURQlLWpZKIqiKGkZMDGLkSNHmsmTJ+d7GIqiKEXFq6++us8YU5vu\nuAEjFpMnT2b58lSZlIqiKEoyRGRL+qPUDaUoiqJ4QMVCURRFSYuKhaIoipIWFQtFURQlLSoWiqIo\nSlp8EwsRWSgie0XkzRT7RURuF5ENIvK620bS2Xe1iKx3Xlf7NUZFURTFG35aFr/ENmBJxXnY+v/T\nse0gfwad9WluwfYCOBG4xSklrSiKouQJ3+ZZGGP+LiKTeznkIuBBY+uNvCgiNSIyFtsqcrExZj+A\niCzGis7Dfo1VURRLS6SDA80R9jdFONjczuHWdowBEds9Cex7u2aIGTAGYsYQS1I6SESQznNwjjed\n5xhjuzcJEAiAIIhAQMT5TunxmQZ7nn1vPy8Z8d9tDHTEDNGYoSMWc5aGWMxQFg46rwCl4SBloSCl\n4QDt0Rhtzqu1vcN539F5XizuGpJfu10GRAgGhFBACAYCztK+DIZYzPkcun428ecL9ocv2Gtojxna\nozGisRjtHYZINMboqjI+9p6JPcaQTfI5KW883dtVbne2pdreAxG5DmuVMHGivz8oJTMOt7bz1zV7\neOGdBk45agQfOm4coaA/hqwxhrg2qIoHoh0xVu88zIsbG3hp037W7jrM/qYIbdFYvoem9IF5E2sG\ntFj0G2PMPcA9APPnzx8QFREPNkd4dcsBVmy1bZJnjqli5pihTBlZ6elma4yhoSnCloYmtjQ0s6Wh\nmd2HWhldVcrkkZVMHlnJ1JGV1FSUZH3sh1qsQDz1xi6eX7+PSEeMipIgj726nZ/8dT2fXTCNj8yt\noySU/DoONkf4+/p97G9sY3RVGaOqyhhTXUbtkNLOcxoa21i98zBv7jzE6h2HWb3zENsPtDBnQg2n\nzxzFghm1zBpblVQ8ItEY6/ceYfXOw7REOigLBzqfKsudZUko0Pk0GnA+w33CTaZHIlBVFmZ4ZQll\n4WCP/fubIryx4xBvuq+dhzjY1J70+msqw5x6VC2nz6jlvUeNZEhpz3/PPYdbWbpuL0vX1fPK5gMM\nqwgzeWQlU0ZWMnlEJZNHVDB5ZCXhYICWSAct7R00R6K0RDpojnSwob6RFzc2sHzzARrbbDvwabWV\nnDx1BCOHllJTEWZ4RQk1FSUMqwhTVR4mIPYJGOwTurUGTOfTf0CEgGNtuBaIcY4lwQqIP0fo+hm7\n1kL8E3asl//oeGsl/nvd70n8boBQsOup3l0CnZZDa3uM1mhHpxVREgxYayMUpDQU6Pz7CAXEuWZB\nAl3XEv/3Ef+9HcZaIq41E40ZOjoM0Vis63OEbhZVouXkrgcDQjgYIBy0y1BQCAcCBAL+PyzlUyx2\n0L0Xcp2zbQfWFRW/falfg2hsi3Ln3zbQFu0gEmd2RqL2DyYgQmko4LyseVoaChAz0NQWpdF52ff2\nD801yTv/sZwn31FVpYyrLmdcTRnjasoZW13OqKpSNtU3sXzLfpZvPsD6vY0AhJxfftT5jykJBZg+\naggzxgxlbHUZzZEOmts6aHJuBE2RKAeb29m2v5mmSEfn9YnAiMpS9je1dfvnq6kIM3lEJSWhgL3m\n9vjr7yBm6PynCogQCtp/rnAg0PkzKA0FO/+ZjrRFWfbOPto7DOOqy7jq5Emcf9xYjq+r4a9r93DH\n39bz1cff4PZnN3D9aVO5dP4ESkMB1uw6zNJ19Sx5ay8rth5IeYMYOaSEYEDYc7itc9uE4eXMHlfN\nGTNH88rm/fz3M+v472fWMWpoKQtm1HLq9FoOtbSz2rlJv727kUiHf0/OZeFA5422qjzEtv0t7DjY\n0rl/4vAKjhtfw6iq0qTule0Hmlm0cgcPv7yVcFB49+ThLJhRy4wxVby0sYEl6+pZu+swAGOqynj/\n9JEcaYuyeV8Tz71dT8SjVXDUqCF8eO44Tpo6ghOnDGfU0LLs/ACUAY2vJcqdmMUfjTGzk+y7ALgB\nOB8bzL7dGHOiE+B+FdsLGGzryxPcGEYq5s+fb/pSG+pAU4T33PYspUH3JmifHkpDAUpCAWLG0Nbe\ndRO1N1b7TzmkLMTQ0hCVpSGGOMvykiBBifeX2ieFWMyw50grOw+2svNgSw9zv6osxAmThjF/8nBO\nmDSM4+tqCATgnb1NvLX7MG/tPmJfuw6zr7GNypIQFaXBzmVFSYiqshB1wyqYPKKCSSMqmTiigrph\n5ZSGgkSiMbYdaGZTfRObG5rYuK+JLQ1NRDsMpeFgD0EMCHTE6PTvuk9G7R0xItEYre1xP49ojIDA\n+6fXcv5xY5lTV9PjSccYw9K367nj2fWs2HqQ2qGlCLD3iL35H1dXzYIZozh9Ri0Th1ew53Abe460\nsudQK7sPt7LncBtt7R0cPbaKY8ZXcczYaqorwt2+Y++RVp5bV8/St+v5+9v1HGm1T841FWFmj6vm\nmHFVHDPeLmvKw7RGY7REOpynSvtkGenoiHt67vJJQ/L/k46YdblZH3+EA83tHGiKcLClnbHVZRw7\nvppjx1dzzLie401GJBpj+Zb9LF1Xz9J1e3l7j314CAaEEyYN4/QZozh9Zi0zRg/tZj3FYoadh1rY\nvK+ZzQ1NxIyhPGz/LipKrNVUURJk/LByRg4pTTuOpBgD7S3QdgQidlwEQhAMQyAMwZBdd20LE3Ne\nzg9UpPvxgSBJzbVsE41AywGItkK0DTra7DLaasdVNQ6qxkM4hWi2HIC9a2HvGtj7FkRb7HVI0LkG\nZxkuh9KhzqvKeTnrJZXOcgiESjO/7kM7YMNfoe0wBEvszzBYat+HSqBiJEw+Jf3nJEFEXjXGzE97\nnF9iISIPYy2EkcAebIZTGMAYc7fYv/Q7scHrZuAat6eyiHwK+A/no75rjLk/3ff1VSzygTGG/U0R\ndh1qZfehViYMr2D6qCGeTcms+eiXfA+OOhMmnNj/z/KIMYZl7zSw8J+bKA0FOX3mKE57Vy21Q/t4\nA0tBtCPGml2HGTGklHHVZUUb09hxsIUNuw8xZ9IIqsvTi02f2LsWXvkFRJqhvdkKQrTFLiPNEDkC\nrYetSJiO9J+XCYFQnHAEbZTbvRFLAGJRiLVDrAM62p33USgfBkPGwNDRMHQsDBkNQ8dARwQO74RD\n2+HwDnuTbdrrbSyVo6C6zr4qa+HAZvuzObKz65jSKnvDNx3O2DqsIMaijvh4sO4CISse5cNg9GwY\nPw/GzYNxc+w2gFgMdr4Gb/8Z3n4adr/R+2eOnw+fedbbdSaQd7HINcUkFgVBWyPcNh5OvgHO+W6+\nR9NFYirIYGfNInjierhuCdTO8Oc7Hv8MrP4dDB1nn67D5RAqt8twRdfTcVlV11NzyRB7bqzduYlH\n7aujHTD2Ri8BbBpPoCslKdnxsXZ7czQdzs3XuRGbWJeYBMPO+5AVlpYDcGS3fTXuscuYEwsqGQrV\n47sshuo6qBjhXFeZfbJ3lybWJS6HtjnL7fYzaybCqFn2NfoYGHW0/bxUf5vGQKTJimrn67B9RZrs\n/1zkiLNshKZ62LkSDmzq+ozhU2HkDNjxqhU5CcCE98C7zoV3nWOvJRqxotjRZn9+0TZrYdS+q0+/\nfq9iUdQBbqUfuH+gkab8jiOeWAz+90po2AAX3ZlTi6dXYh32KbUmDxl3L/4M2pvgz1+HKx/Pvoga\nA5ueg1kfho/el93PziWxmBWQYAjKqvMzBhEoHWJfjPV+XvN+2LXSWhI7VkD9Oph8qhWI6WdBxfDu\nx2fXCPeMigXYm0GgZyZLQdJ2BBr3wohp/fuc/Y5YtDf3f0zGwJFd9kmuP7zwU1j3JyirgYXnwHs/\nD6f/h30CzCev3g9/+hJMfh+c+kWYdkZuLJ/6t2HrC1B7NLzzLKz/i326zOp3vGWfoqeelt3PzTWB\nAFSOyPco+kbFcPs3Ne2MfI+kV7Q21OFdcPf74O1n8j0Sb/z2k/CzU+CAp34lqTmQRbFY/A348dHw\ni7Ng9RPQEc38M7a+BM9+2z7hfuENmHsl/PMncM8Ca6rnk3eWWF9ywzvwq4vtmFY/aR8y/GTFA9bt\ncuXjMOIoeOY/rAsim2xcapdTF2T3c5UBh4pFSYXNJvjfT9ibQiGz63WbERFtgaf+vXsyd6bs32iX\nkX6KxT9/Ci/cDtPPsT7Y334Sbp8D/7wdWg56+4zm/fDYp6w/9sLbrW/8wjvg449Z18IvPgBLv+/4\nw3OMMbD1ResSuGmlHVfbEfjt1XDXifDar/v3e0hFtA1WPQwzzrP+93O+Z91zr9yb3e/Z+Jz1k+fD\nxaYUFSoWZdVw5e+sW+eRj8GWZfkeUWr++RMbvHv/V2D9M7D2D33/rGy4oV77tbUqjvkIXPEw3Pgq\nXP4bqJkEi/8L/ucYeOorNviYCmPg95+zrpBL7+/ub55+Fnx2Gcy+BJbeBg99xJ8bc280bIDmfTDx\nZOsOm3cV3PAKXPpLG/z9/Wf793tIxVt/guYGmPdJuz79bJu5tvQH0LQvO9/REYXN/4ApRe6CUnKC\nigVYn+FVv7c+919faoNM6ehoty6sXa/Dhmdh1SPwwh2w4kF/xrh/k3XxzL8GTvsqjD4Wnv6qfcrt\nC/0NcK97GhbdaN0XH/m5jfkEgjDzArjmT3DdczDzg7B8Idz5bnjx7uTuqZd+DuuegrNuhfEn9Nxf\nPgwuvsdmbW1+3j5x55KtzsPDxJO7tgWCViCvW2rz29c8mf3vXfEAVE+AaafbdRFrXUQaYUmWstd2\nrrDZOVMXZOfzlAGNioXLkFFw1SIrHL+6GPas7nlMNAKvPwr3fgC+PRJ+PBN+/j57/BP/B/5ys72B\n9jeekIxld1r/9UmftRkfH/qJDSov+V7mnxWN2PRAsLn0mbJlmXU3jT0eLvtV8gD0uDlw8c/hcy9B\n3bvhz1+FexfAtle6jtmxwv7MZpwPJ/1r799Z5ZQHi7ZmPt7+sPVFKB8OI6f33OeK49vPQLvHcb18\nL6x4qPdj9m+ysYS5n+ieeFE7A078DLz6S9idtPJ/ZmxcCghMeX//P0sZ8KhYxFM9Hq5eZHPMH7wI\n9q2324/shiW3WbfK7z4DrYfg/f8OF/wY/uUhuObPcOMKKzZgU+CySWM9vPYrOO4yqHJS8urmWyvj\npbth16rMPu/gVptfHizN3A21+034zWX2qffjv7V5970xYpoN0F76ADQ1wH1nwqLP2wlPj11jJ1Nd\ndFf67CJ3dm3OxWKZtSpSje/oC+3Tvhso7o2Wg/DMf9oHit6Of+0hm18/98qe+077qnXV/flr/XfJ\nbVwKY4/rmZqpKElQsUhk2GQrGAAPXAiPXQv/Mxue+wGMm2vjG597Gc64Gd59Lcy6ECadbG+KE0+y\nE4h2enBjZcLLP7ful1Nu6r79A7fYyUZ/+EJmmTmuC2rUzMzcUAe2wK8usbNPP/E7qBzp7TwROObD\ncMPL1p302q/gp3Pg4Dab2+/lZhXKg1gc2WMTASaelPqYKe+H0mpvcYvVT9iJVENGw++usynQiXRE\nbSzoqLPsw0siFcPh9P+0Lrm3/uj9WhKJNMG2l9UFpXhGxSIZI6fDJ560WUfr/2JN/xtfhY8/Ckd9\nwOZ0JyNUCmNme4t5eKWt0bouZl7Q0xVSXgPn3GbFaflC75/pZkKNOiYzN9Ty+2zQ9RO/61v2TOlQ\nO1v8+udtwPb8H/Z+I47HFQuv7p7e2LPaWjnp2PaiXcbHK3qMqwRmnGvnh6TL1lr1MNTOtD+/1kPW\ndRlLKA+x/hlo3A0n9NIg8oRr7NyLv9xsP6cvbFlmZzxPXdC385VBh4pFKsbMtq6lf1sL597mfRLc\nuLnWLZR4E+grKx6A1oN2Mlgyjv2o/Yd/9lb7JOyF/ZsgXGmtqI4271ZJ6yH7ZDvqaG/Hp2L0MVZ4\n3/1p7+f017Job7FP7PcsgJ+9F568Pv05W1+0Lsmxx/d+3NEX2hTfLf9MfUzDO7DtJTj+Cnv9594G\n7/zNTkSM59UHbM2j6b1MvguG7PkHNsMPp9kssZfvtZaaVzYusSUiJngUa2XQo2LRGxXDnan7GTBu\nnq0Fs/+d/n9/NALL7oJJp9oYRTJEbOwk2gbPfN3b5x7YBMOn2Dkm4N0VFWmy6aL5oK8xi/2b7BP4\nj4+2aa6RZpsquuFZGwvqja3L7M89lKb3x7Qz7M9lzaLUx6x62MYhjrvMrp9wjZ2A+Oy3rTsInMqi\ni2Hux60g9Pqdp8On/wYnXW9jUE99GX4yG+4+1SY9pLu2Tc/ZmkMlefp9KkWHikW2Ge9UVs+GK+rN\nx2xNolO/0PtxI6bZeMabj9unzXTs32itCvfG7zXIHWnuKiCXazK1LGIxO9Hy9rmw7P/Z2MLVf7DZ\nWed+3xarW/1E6vPbGm1atBc3WUmFnQPx1h+TW5SxmE2tnnp6V4KCiJ2AWF1nJyS2HLCxHBOzWVBe\nqDsBzv6OdZHesNymH5cMgb//t500mCoA3rTPVjGdusDb9ygKKhbZZ+QM67rob0ZULGZnR4+ebW9E\n6Zh5vl2m+95YzAaqh0/tg1g05u9JNNOYRct+WLvIzof44pvwLw9awRCB0bPsz/WNR1Ofv/0VKyhe\nYyqzLrITC7e/0nPfln/YiqZzPtZ9e1k1fPR+mwL9+xtsFtTUBdbqy5SR0+0Dw6f+bC3NLf+EN36b\n/NhNz9nl1AWZf48yaFGxyDbBkPVx9zcjav0ztsjbKTd5K1o3apbNxEqXRntkp41TdHNDeRSL9mab\nCZUPMrUs3MD9tDOSFzg89lJ7Y3eD/YlsfdG6jeo8Vr6dfraNAaxN4opa+bAt6z3zgp776k6AM79p\nrZJD22BeL4Ftr8y72k5wTBUA3/iczeAaO6f/36UMGlQs/GD8POvC6EtBPZeXfg7VE+GYi70dHyq1\nged0Rffcm+OwKTbIDRlYFkUUs3CPC5cn3z/7Ert847Hk+7cus4Hosipv31dWZd1Maxd1d/+0NcKa\n39vU4VRjOelzdmJi9YTkgpIpgQCc/yObmrvktp77Ny6FKe9LHxdRlDhULPxg3Fybdlu/tu+fcXAL\nTHh3Zv/QY4+3lkVvk7XcmlDxlkUmYlEsMQvXskhV3rxmAkw6xc7IT/x5dbTD9uW9p8wm4+gP2WDz\n7te7tq39g+1HcfzHUp8XCNiaWp9dlr1y7OPn2UmbL/+8e5e1/Zvs35bWg1IyRMXCD8Y5Qe7+xC3a\nGjO/MY893vrq3VIeyTiwybqrquq6nnS9uqEiTcUTs3BFJZTiaR6sK6phfU/X3e437A0+U7GYcb5t\nBxqfFbXqNzaZIF3sQyT9bPhMOeO/bG2tP325SxA1XqH0ERULPxg+1fqE+5MRFWnM/OYxbq5d7urF\nFbV/o51QFwxl7oYqxpiF675KxqyLrHAmBoK3upPxMpyDUDkCJp/SNZv74DbY9LydW5GPNrEVw+HM\nb9nJhasetts2LrXtU5PVulKUXlCx8INAwBbS62uQuyNqb8yZisXoY+yTbW9B7v2burJtMnFDxWL2\nuHCRiIUXy6JiuC2D/sZj3Scmbl1my6z3pfPf0RfCvnW2NebrjwAGjr8888/JFnM+bgs5/uW/bN+Q\njc/Zrnja41zJEBULvxg3F/as6Vt5ikijXWbqhgqX23ISqcTCGDsPY/hU5/gMsqFcQcmXZREI2Gyj\nbFoWYF1RjbttXwfoanaUqQvKZeYH7XLNIpsFNekU64bKF4EAXPB/rXvy0avscuqC/I1HKVpULPxi\n/DxbeydZqfN0uGKR6exxcNJ2VyYPcjc32NnlwxzLonOehYcZ3O4s73zO+A2VZxCzcPpehNKIxYzz\nbEMpd87F/o3QtDdzF5RL1VibbvviXXYW//FX9O1zssnY421plc3P23UNbit9QMXCLzqD3H1wRbX1\n0bIAe2No2pu8O118JhTYzBsJeLQsXLHIUzYU2PF6dkO5lkUvbih3/9EfspZAe2vyZkeZMsupFRUq\nt3GRQuD0/7SNmmpnds0iV5QMULHwi+o6+8/Zl4yoTsuiD9kx45yJVslcUW5pctcNJWKtCy+VZ13L\nIl/zLMC6lDy7odyYRRrLAmwxxrbDdiLk1mW22VHtjL6P8+gPdS29ztPwm/Ia2w3ykvvyPRKlSNFZ\nOX4hYl1RfcmIclul9kUsRs8GxGZEzTi3+779G+2+mkld28IVHt1QeY5ZgL3xey2p7loWXsRiymlQ\nOcpmRe1da11Q/QkAD5sMH11oC/UVEmNm53sEShGjloWfjJtnM2Nct5JX+hrgBhvnGDk9uWWxf5PN\n8IkP+pZUeHNDdY4pz2LhtQd3JpZFMGRndK/7MzRs6Hu8Ip7Zl1jrUlEGCCoWfjJurq0iGj+j1wud\nlkUf4wNj56R2Q7kuKJdwpbfU2XxnQ4EjFhlYFsHS1I2qEjnuUpuQAP2LVyjKAEXFwk/6Wq68M8Dd\nxxm9Y4+3pc0Texq4pcnjCZd7E4uCiVlkYFmkS5uNZ9w8K6ShsvTNjhRlEKIxCz8ZMsqW1cg0IyrS\nX8vCudntWgXTnfLmbUegqb5n+WvPbqhCyIYqg9bD3o6NtvQ+IS8REdsbYv+m7NVnUpQBhIqF34yb\nk3lGVFujnYntxd+ejLHH2eWulV1i4TZFSuaGajmQ/jMLYp6Fj5YFZKfiq6IMUNQN5Tfj51n3j5cb\nskuk0VoVfc3IKau2ohBfIyq+NHk84XJvGUauqyqfbqiMYhatmVkWiqL0ioqF3/SlAm1bo22W0x/c\ncuUuiRPyXDLJhgqVQyDYv3H1h0xiFtE+WBaKoqRExcJv3ElyGYnF4f7HBsbOsb0Vmvfb9QOboGKE\ntTriCVd6n2eRz0woyGyeRXuGMQtFUXpFxcJvyodZl1AmGVGuG6o/xAe5wcmEStLb2asbKp+9LFwy\niVlEWzVQrShZxFexEJFzRWSdiGwQka8l2T9JRJ4VkddFZKmI1MXt6xCRlc4rSWPjImLcvMzdUP22\nLBLFYnNPFxRYa6Ejkr4FbHseu+S5uDGL3joBurS3pq8LpSiKZ3wTCxEJAncB5wGzgCtEZFbCYT8C\nHjTGHAfcCsQ3DG4xxsxxXhf6Nc6cMH6enfdwZI+347NhWVQMt02Odq2yT+OHt/fMhALvlWfz2X/b\nxY1BdETSHxtt6Xs2maIoPfDTsjgR2GCM2WiMiQCPAIklOGcBf3PeL0myf2Aw5li73LvG2/FtjX2f\nkBfP2ONtRtTBrXYmeTI3VInHnhaFErMAj9lbalkoSjbxUyzGA9vi1rc72+JZBVzsvP8IMFRERjjr\nZSKyXEReFJEPJ/sCEbnOOWY7NqaiAAAgAElEQVR5fX19skMKg4qRdtl6yNvxkSPZ6cc8do6NVbiu\nqGRuqLDHbnmRpsIRCy9xC7UsFCWr5DvA/WXgNBF5DTgN2AG4/S0nGWPmAx8DfiIi0xJPNsbcY4yZ\nb4yZX1tbm7NBZ4ybgeRFLIxxUmezEB8Y62RirXnSLpMGuD2KRXshiYVaFoqSa/ycwb0DmBC3Xuds\n68QYsxPHshCRIcAlxpiDzr4dznKjiCwF5gLv+Dhe/8hELNpbwHRkJ5jsBrnXL7YpskNG9TzGsxuq\ngGIWniyLVrUsFCWL+GlZvAJMF5EpIlICXA50y2oSkZEi4o7h68BCZ/swESl1jwFOATw6/AuQkkpb\nvsOLWPSn8VEiQ2qhary9cQ6fknxGuGc3VHNhZENB+phFR7sVXJ2UpyhZwzexMMZEgRuAZ4C1wKPG\nmNUicquIuNlNC4B1IvI2MBr4rrP9aGC5iKzCBr6/b4wpXrEQsdaFF7Fwy5Nn68bsWheJ1WZdvIiF\nMVbECmGeBaS3LFwx0Ul5ipI1fC0kaIx5CngqYds34t4/BjyW5LwXgGP9HFvOKavK0LLIoliseyp5\n2ix0xSF6c0NFWwFTPDELt/WqTspTlKyR7wD34MGzZZFFNxR0BbmTZUKBN8uis5dFnsXCa8zCtSw0\nwK0oWUPFIld4FYtIPxsfJTL5FJj9UZh+dvL97g3Vi1gUimWRLmYRzaClqqIontB+FrmirBoaPCRz\n9belaiKlQ+Gj96Xe3+mG6mUGdyH0soDMYxZqWShK1lDLIlfkK8CdjmCJzdTqzbLo7L9dINlQnmMW\nalkoSrZQscgVZTX5CXCnQ8TGLXpz7bhjyvs8C8dSUMtCUXKOikWuKKu2N9101V3dAHcun+JLKtK4\noVzLIt8xCye7KW3MwhETtSwUJWuoWOQKt/Nd2+Hej4s02if4XHakC1cUV4A7nWURVctCUbKNikWu\n6Cz5cbD349qyVEQwE9K5odoLRCwCQQiE08cs2nWehaJkGxWLXOG1PlTbkdwHktO6odx5FnmOWYC1\nFrxaFjqDW1GyhopFrvAqFtlofJQpad1QBRKzAGstpItZuJaF1oZSlKyhYpErOsUiTcwiW42PMqGk\nsvdyH5FGm2IbDOduTKkIqWWhKPlAxSJXeLYsjuTBsihPP8+iEKwKsJaFp5iFaMxCUbKIikWu8Byz\naMx9zMJLNlS+60K5hMu8WRahsuQl2RVF6RMqFrmiZAhIwGPMotDcUAXQJc8lVOYtZqHxCkXJKioW\nuSIQsCLgxbIoNDdUpCn/daFcQl4si1aNVyhKllGxyCXp6kN1RK0LJdcB7nAlxNpth7lktBdAlzyX\nUJm32lBqWShKVlGxyCXpxCKS5YqzXunsw51iroU7q7wQ8BKzaG/RUh+KkmVULHJJumKC+agLBXE9\nLVI8sUcKKRvKQ8wi2qpioShZRsUil6S1LHJccdbFzXRKFbcotphFe6vWhVKULKNikUvKqnsvJNjZ\nUrUqN+NxSeeGam8qspiFuqEUJduoWOQSrzGLfMyzgN4ti6KKWahloSjZRsUil5RWWcsi1pF8f7Zb\nqnqlN7GIRiAWLbyYhTGpj1HLQlGyjopFLnFncadyReUrwN3phkoiFm4cpZDEApM6zRd0Up6i+ICK\nRS5JV/KjM8Cdh3kWkNyyaC+girPgrQ+3TspTlKyjYpFL0olFW75iFm7qbDLLooB6WUCXxdBb3CLa\nqkUEFSXLqFjkEi+WRSCU+xtdr24ot0teAWVDQeq5FsbYfRrgVpSsomKRS9JaFk4RwVxXS+10QyVJ\nne0UiwKxLNL14e6IAEYD3IqSZVQsckm6BkiRPDQ+AtvUSILJLYtii1m4FodaFoqSVVQscomXmEWu\n02bBWjIllcldO27QvZD6WUBqyyLqtFRVy0JRsoqKRS5xs5x6E4t8xQbCFSncUAVqWaSKWahloSi+\nkFYsRORGERmWi8EMeAJBOzGvtwB3PiwLsDGJXgPchSIWjgioZaEoOcWLZTEaeEVEHhWRc0W0V2W/\n6K3kRz5aqrqEK5I/rbcXmlg4mWIas1CUnJJWLIwxNwPTgfuATwLrReR7IjLN57ENTHoTi0hj7osI\nuqR0QzXZ4HewJPdjSkY4nWXhbFfLQlGyiqeYhTHGALudVxQYBjwmIj/0cWwDk3SWRcG5oZwueYVi\nULqWRaqYhWtxqFgoSlbxErO4SUReBX4I/BM41hjzr8AJwCVpzj1XRNaJyAYR+VqS/ZNE5FkReV1E\nlopIXdy+q0VkvfO6OuMrK1RSiYUxtupsXt1QKWpDFcocC0gfs2h3YhZaG0pRskrIwzHDgYuNMVvi\nNxpjYiLywVQniUgQuAs4C9iOjXssMsasiTvsR8CDxpgHROQM4DbgEyIyHLgFmA8Y4FXn3AOZXFxB\nUlYNbW/23N7eDCaWP8silVi0F1CXPEgfs+i0LDRmoSjZxIsb6mlgv7siIlUi8h4AY8zaXs47Edhg\njNlojIkAjwAXJRwzC/ib835J3P5zgMXGmP2OQCwGzvUw1sInVTZUvirOuvSWDVUodaEgfcxCLQtF\n8QUvYvEzoDFuvdHZlo7xwLa49e3OtnhWARc77z8CDBWRER7PRUSuE5HlIrK8vr7ew5AKgLJqO4M7\nFuu+PV8VZ13ClakLCRZKXSiw6ceBsIeYhVoWipJNvIiFOAFuwLqf8Oa+8sKXgdNE5DXgNGAHkKIz\nUE+MMfcYY+YbY+bX1tZmaUg+U1YNmK6ueC75qjjrEi7vRSwKyLKA3vtwq2WhKL7gRSw2isjnRSTs\nvG4CNno4bwcwIW69ztnWiTFmpzHmYmPMXOA/nW0HvZxbtKQq+ZFvy6KkwnbEi0a6by+0mAU4rVXV\nslCUXOJFLK4H3ou9WW8H3gNc5+G8V4DpIjJFREqAy4FF8QeIyEgRccfwdWCh8/4Z4GwRGebMHj/b\n2Vb8pBKLfLVUdUlVeTbSVDh1oVzSWRYSsMURFUXJGmndScaYvdgbfUYYY6IicgP2Jh8EFhpjVovI\nrcByY8wiYAFwm4gY4O/A55xz94vIt7GCA3CrMWZ/jy8pRlKKhRvgzlfMwm2A1ALlcdVdIk2FZ1m4\nfbiT4XbJK5R5IYoyQEgrFiJSBlwLHAN0OoKNMZ9Kd64x5ingqYRt34h7/xjwWIpzF9JlaQwcUrqh\n8mxZuIKQmBFVbDEL7ZKnKL7gxQ31EDAGm876HDZ+cKTXM5TUpOppke/UWTc9Nt4N1RGFjrbCyoaC\n3mMW7a1aF0pRfMCLWBxljPkvoMkY8wBwATZuofSFdAHufGZDQXfLor3A+m+79GpZtGipD0XxAS9i\n0e4sD4rIbKAaGOXfkAY4bqHAZDGLkiEQyFOLEdcNFZ8+W2i9LFx6i1moZaEovuBlvsQ9TkbSzdhs\npiHAf/k6qoFMMGRFIVnMIp/unk43VLxYFFh5cpdQqVoWipJjehULJ631sFNy4+/A1JyMaqCTrJhg\nvlqquiQLcBdaLwuXcLnGLBQlx/Tq83Bma38lR2MZPJRVQ+vB7tvy2fgI4lJnk1gWBRezUMtCUXKN\nFwf5X0XkyyIyQUSGuy/fRzaQSWZZRBrzN3sbUrih3JhFgWVDhcrTxCxULBQl23iJWVzmLD8Xt82g\nLqm+U1YNh3d239bWCNV1yY/PBcncUJ0ZWsVkWbSqZaEoPuBlBveUXAxkUFFWDfVvdd8WOZJfyyIY\nhkCo+zyL9gLNhnJjFsb0nKmtYqEovuBlBvdVybYbYx7M/nAGCcl6WuSzpapLuLK7e6czZlFgYhEq\ntY2iYtGeNaDaWzTArSg+4MUN9e6492XAB4AVgIpFX3FjFvFPxm15Tp0FpwFSnGVRsKmzcXWsEsVC\nLQtF8QUvbqgb49dFpAbb9U7pK2XV9snYDWp3tNuyGvl0Q0HPnhaRJkAK70m9s7VqK1DVtd0Yu63Q\nxqsoA4C+TBduAjSO0R8SS37ku/GRS6Ibyu1lUWgVXDtbq7Z23+6uq2WhKFnHS8ziD9jsJ7DiMgt4\n1M9BDXjixaK6Lq7xUaG5oRoLb44FdIlBe4JYuEKnloWiZB0vMYsfxb2PAluMMdt9Gs/goIdlkeci\ngi7hii7hAptGW2jxCugSC7UsFCVneBGLrcAuY0wrgIiUi8hkY8xmX0c2kEkUi07Loir58bkiXAFN\n9V3rhdj4CFKLhVoWiuIbXmIWvwVicesdzjalryT2tMh3S1WXRDdUe4GKRTiVZeFM1NPmR4qSdbyI\nRcgYE3FXnPcl/g1pEFCwAe6KntlQhSgWqWIWbnHBkFoWipJtvIhFvYhc6K6IyEXAPv+GNAhI7GlR\nKAHucEVCuY/mwg5w93BDOetaG0pRso6XmMX1wK9F5E5nfTuQdFa34pFQib0Ju5VnOwPceZ5nUeJY\nFu5kwUieK+GmImWAWy0LRfELL5Py3gFOEpEhznpjmlMUL8RXno0USMwiXAGmAzoi1u/f3lx4RQQh\ndcxCLQtF8Y20bigR+Z6I1BhjGo0xjSIyTES+k4vBDWjixaKtEYIl+Q/MdlaebepaFlXMwk2dVctC\nUbKNl5jFecaYzk49Tte88/0b0iChm2VRIO6ecFzNpVjMWhaFVkQQPKTOqmWhKNnGi1gERaTzkVdE\nygHNTewv3SyLPLdUdXGFob25cMuTg4dJeWpZKEq28RLg/jXwrIjcDwjwSeABPwc1KCitgoYN9n1b\nY/6D29AVn4g0xYlFAcYsgiHbe0MtC0XJGV4C3D8QkVXAmdgaUc8Ak/we2IAnMcBdEJZFXB/uSIGU\nIElFqCxJzKKta5+iKFnFa9XZPVihuBQ4A1jr24gGC/E9LdoKJWYR54Zy51sU4jwLsIKQLHVWgj17\nXCiK0m9SWhYi8i7gCue1D/hfQIwxp+dobAObsmrb6c19iq+ZmO8Rxbmhmgu38ZFLMrFo114WiuIX\nvbmh3gKeBz5ojNkAICJfzMmoBgPxJT8KoaUqdFkR7c1dvbgLVSzCKSwLdUEpii/05oa6GNgFLBGR\ne0XkA9gAt5INuonFkcIIcMeLRTFYFj36WahloSh+kVIsjDFPGmMuB2YCS4AvAKNE5GcicnauBjhg\nccWi5aDTXrUALItubqgijVmoZaEovpA2wG2MaTLG/MYY8yGgDngN+KrvIxvouGJxZBdgCiTAHW9Z\nFEE2VNKYhYqFovhBRj24jTEHjDH3GGM+4NeABg2uWBzeYZeFYFkEwxAIJ0zKK1DLImXMQt1QiuIH\nXiblKX7gisUhRywKIWYBTgOk5i53TiG7oZLFLPJdX0tRBigZWRaZIiLnisg6EdkgIl9Lsn+iiCwR\nkddE5HUROd/ZPllEWkRkpfO6289x5gW3p8Vhp515aYGIRbjSZkJFmuxTeiCY7xElJ2nMQgPciuIX\nvlkWIhIE7gLOwvbAeEVEFhlj1sQddjPwqDHmZyIyC3gKmOzse8cYM8ev8eWdcJm94R0qIDcU2Jtt\npBmCpYWbCQWpxUID3IriC35aFicCG4wxG51WrI8AFyUcYwDnEZtqYKeP4yk8yqrhkGNZFEoguaTC\n1lgq1F4WLsliFu0talkoik/4KRbjgW1x69udbfF8E7hSRLZjrYob4/ZNcdxTz4nI+5J9gYhcJyLL\nRWR5fX19FoeeI8qqoWmvfV9wbqgCKUGSiqS1odSyUBS/8DVm4YErgF8aY+qwPTIeEpEAdjLgRGPM\nXODfgN+ISFXiyU5m1nxjzPza2tqcDjwruEFuKJwbs+uGKtT+2y5a7kNRcoqfYrEDmBC3Xudsi+da\n4FEAY8wyoAwYaYxpM8Y0ONtfBd4B3uXjWPNDaZz+FUrMoqTSunMKtUueS6jMaQHb3rVNJ+Upim/4\nKRavANNFZIqIlACXA4sSjtkKfABARI7GikW9iNQ6AXJEZCowHdjo41jzQ6dlIYXTkS5cYd1Q7QUu\nFol9uGNO73C1LBTFF3zLhjLGREXkBmz/iyCw0BizWkRuBZYbYxYBXwLudQoUGuCTxhgjIu8HbhWR\ndiAGXG+M2e/XWPOGKxYlQyCQb4+ggzvPQgKFLRbxfbhLh8Z1yVPLQlH8wNdJecaYp7CB6/ht34h7\nvwY4Jcl5jwOP+zm2gsAVi0JxQYFjWThiUegxC+gSiXYVC0XxE53BnU/iLYtCwRULpLDGlUiiWLhL\nrQ2lKL5QIL6PQUohWhYlFWBittVroc+zgJ5iobWhFMUXVCzySaFaFi7FErMAm8EFalkoik+oWOST\nTsuiQCbkQXexKJQMrWSkckOpZaEovqBikU8KUSzirYlisCyialkoSi5QscgnBe+G0piFoigWFYt8\nUogB7vhJbYUkYolozEJRcoqKRT4pq4FgCVQWUF2reNdTMc2zUMtCUXxF51nkk3AZXLsYRhyV75F0\nUWzZUIkxC+2Upyi+oGKRb8YVWH+nbm6oAhaLHjGLNme7WhaK4gfqhlK6U2zZUG7MItrSfbuiKFlF\nxULpTrd5FgUcswiGQYI9a0OpZaEovqBioXSnWGIW0L0BUrQFAmEIBPM7JkUZoGjMQulOMGQztMA+\nvRcy8X24tUueoviKioXSk3AFiOR7FOmJ78OtXfIUxVdULJSelFQCRSIW3SwLFQtF8QsVC6Un4XIb\nPC50EmMWalkoim+oWCg9CVcUR6A4MWahYqEovqFiofSkYkRxiEVizEID3IriGyoWSk8uvJ2iiVm0\nHrLvo21qWSiKj6hYKD2pmZjvEXgjVAbRPfZ9ewuUD8vveBRlAKOT8pTiJT5mEdWYhaL4iYqFUrzE\nxyx0Up6i+IqKhVK8aOqsouQMFQuleOkxKU8tC0XxCxULpXgJJ1oW2vhIUfxCxUIpXkJlEItaqyIW\n1ZaqiuIjKhZK8eLGKFoP2qXWhlIU31CxUIoXVyxaHLFQy0JRfEPFQilewmpZKEquULFQihe1LBQl\nZ6hYKMVLp1gcsEu1LBTFN1QslOIlMcCtloWi+IaKhVK8hBMsC51noSi+4atYiMi5IrJORDaIyNeS\n7J8oIktE5DUReV1Ezo/b93XnvHUico6f41SKlMSYhc7gVhTf8K1EuYgEgbuAs4DtwCsissgYsybu\nsJuBR40xPxORWcBTwGTn/eXAMcA44K8i8i5jTEcmY2hvb2f79u20trZm45KKgrKyMurq6giHw/ke\niv8kxiy0NpSi+Iaf/SxOBDYYYzYCiMgjwEVAvFgYoMp5Xw3sdN5fBDxijGkDNonIBufzlmUygO3b\ntzN06FAmT56MSBE08+knxhgaGhrYvn07U6ZMyfdw/KfHpDy1LBTFL/x0Q40HtsWtb3e2xfNN4EoR\n2Y61Km7M4FxE5DoRWS4iy+vr63sMoLW1lREjRgwKoQAQEUaMGDF4LKlwYuqsWhaK4hf5DnBfAfzS\nGFMHnA88JCKex2SMuccYM98YM7+2tjbpMYNFKFwG1fWqZaEoOcNPN9QOYELcep2zLZ5rgXMBjDHL\nRKQMGOnxXGWwozELRckZfloWrwDTRWSKiJRgA9aLEo7ZCnwAQESOBsqAeue4y0WkVESmANOBl30c\nqy80NDQwZ84c5syZw5gxYxg/fnzneiQS8fQZ11xzDevWrfN5pEVKjxncKhaK4he+WRbGmKiI3AA8\nAwSBhcaY1SJyK7DcGLMI+BJwr4h8ERvs/qQxxgCrReRRbDA8Cnwu00yoQmDEiBGsXLkSgG9+85sM\nGTKEL3/5y92OMcZgjCEQSK7b999/v+/jLFqCYZAAxNohWAopfoaKovQfP91QGGOewgau47d9I+79\nGuCUFOd+F/hutsbyrT+sZs3Ow9n6OABmjavilg8dk/F5GzZs4MILL2Tu3Lm89tprLF68mG9961us\nWLGClpYWLrvsMr7xDftjOvXUU7nzzjuZPXs2I0eO5Prrr+fpp5+moqKC3//+94waNSqr11RUiDh9\nuJvVqlAUn9FHsTzx1ltv8cUvfpE1a9Ywfvx4vv/977N8+XJWrVrF4sWLWbNmTY9zDh06xGmnncaq\nVas4+eSTWbhwYR5GXmC4IqF1oRTFV3y1LAqJvlgAfjJt2jTmz5/fuf7www9z3333EY1G2blzJ2vW\nrGHWrFndzikvL+e8884D4IQTTuD555/P6ZgLElcs1LJQFF8ZNGJRaFRWVna+X79+PT/96U95+eWX\nqamp4corr0w6V6KkpKTzfTAYJBqN5mSsBY1rUWjarKL4irqhCoDDhw8zdOhQqqqq2LVrF88880y+\nh1Q8qGWhKDlBLYsCYN68ecyaNYuZM2cyadIkTjklacxfSUZILQtFyQViM1WLn/nz55vly5d327Z2\n7VqOPvroPI0ofwyq6154Hmx9AaaeDlc9me/RKErRISKvGmPmpztO3VBKcaMxC0XJCSoWSnGjMQtF\nyQkqFkpxo2KhKDlBxUIpbnRSnqLkBBULpbhxRSKkMQtF8RMVC6W4UctCUXKCioWPZKNEOcDChQvZ\nvXu3jyMtYkJqWShKLtBJeT7ipUS5FxYuXMi8efMYM2ZMtodY/KhloSg5YfCIxdNfg91vZPczxxwL\n532/T6c+8MAD3HXXXUQiEd773vdy5513EovFuOaaa1i5ciXGGK677jpGjx7NypUrueyyyygvL+fl\nl1/uViNq0BPWbChFyQWDRywKiDfffJMnnniCF154gVAoxHXXXccjjzzCtGnT2LdvH2+8YUXt4MGD\n1NTUcMcdd3DnnXcyZ86cPI+8ANFyH4qSEwaPWPTRAvCDv/71r7zyyiudJcpbWlqYMGEC55xzDuvW\nrePzn/88F1xwAWeffXaeR1oE6DwLRckJg0csCghjDJ/61Kf49re/3WPf66+/ztNPP81dd93F448/\nzj333JOHERYRKhaKkhM0GyoPnHnmmTz66KPs27cPsFlTW7dupb6+HmMMl156KbfeeisrVqwAYOjQ\noRw5ciSfQy5cwhrgVpRcoJZFHjj22GO55ZZbOPPMM4nFYoTDYe6++26CwSDXXnstxhhEhB/84AcA\nXHPNNXz605/WAHcy3JRZTZ1VFF/REuUDkEF13W1H4LkfwOk3q3WhKH3Aa4lytSyU4qZ0KJz9nXyP\nQlEGPBqzUBRFUdIy4MVioLjZvDLYrldRlNwwoMWirKyMhoaGQXMDNcbQ0NBAWZn67hVFyS4DOmZR\nV1fH9u3bqa+vz/dQckZZWRl1dXX5HoaiKAOMAS0W4XCYKVOm5HsYiqIoRc+AdkMpiqIo2UHFQlEU\nRUmLioWiKIqSlgEzg1tE6oEt/fiIkcC+LA2nmNDrHlzodQ8uvFz3JGNMbboPGjBi0V9EZLmXKe8D\nDb3uwYVe9+Aim9etbihFURQlLSoWiqIoSlpULLoYrF2G9LoHF3rdg4usXbfGLBRFUZS0qGWhKIqi\npEXFQlEURUnLoBcLETlXRNaJyAYR+Vq+x+MnIrJQRPaKyJtx24aLyGIRWe8sh+VzjNlGRCaIyBIR\nWSMiq0XkJmf7QL/uMhF5WURWOdf9LWf7FBF5yfl7/18RGZA9ekUkKCKvicgfnfXBct2bReQNEVkp\nIsudbVn5Wx/UYiEiQeAu4DxgFnCFiMzK76h85ZfAuQnbvgY8a4yZDjzrrA8kosCXjDGzgJOAzzm/\n44F+3W3AGcaY44E5wLkichLwA+B/jDFHAQeAa/M4Rj+5CVgbtz5YrhvgdGPMnLj5FVn5Wx/UYgGc\nCGwwxmw0xkSAR4CL8jwm3zDG/B3Yn7D5IuAB5/0DwIdzOiifMcbsMsascN4fwd5AxjPwr9sYYxqd\n1bDzMsAZwGPO9gF33QAiUgdcAPzCWRcGwXX3Qlb+1ge7WIwHtsWtb3e2DSZGG2N2Oe93A6PzORg/\nEZHJwFzgJQbBdTuumJXAXmAx8A5w0BgTdQ4ZqH/vPwG+AsSc9REMjusG+0DwFxF5VUSuc7Zl5W99\nQPezUDLDGGNEZEDmUovIEOBx4AvGmMP2YdMyUK/bGNMBzBGRGuAJYGaeh+Q7IvJBYK8x5lURWZDv\n8eSBU40xO0RkFLBYRN6K39mfv/XBblnsACbErdc52wYTe0RkLICz3Jvn8WQdEQljheLXxpjfOZsH\n/HW7GGMOAkuAk4EaEXEfEgfi3/spwIUishnrVj4D+CkD/7oBMMbscJZ7sQ8IJ5Klv/XBLhavANOd\nTIkS4HJgUZ7HlGsWAVc7768Gfp/HsWQdx199H7DWGPPjuF0D/bprHYsCESkHzsLGa5YAH3UOG3DX\nbYz5ujGmzhgzGfv//DdjzMcZ4NcNICKVIjLUfQ+cDbxJlv7WB/0MbhE5H+vjDAILjTHfzfOQfENE\nHgYWYMsW7wFuAZ4EHgUmYku8/4sxJjEIXrSIyKnA88AbdPmw/wMbtxjI130cNpgZxD4UPmqMuVVE\npmKfuIcDrwFXGmPa8jdS/3DcUF82xnxwMFy3c41POKsh4DfGmO+KyAiy8Lc+6MVCURRFSc9gd0Mp\niqIoHlCxUBRFUdKiYqEoiqKkRcVCURRFSYuKhaIoipIWFQtFyQAR6XAqerqvrBUgFJHJ8RWBFaWQ\n0HIfipIZLcaYOfkehKLkGrUsFCULOH0Efuj0EnhZRI5ytk8Wkb+JyOsi8qyITHS2jxaRJ5x+E6tE\n5L3ORwVF5F6nB8VfnNnXipJ3VCwUJTPKE9xQl8XtO2SMORa4E1sVAOAO4AFjzHHAr4Hbne23A885\n/SbmAaud7dOBu4wxxwAHgUt8vh5F8YTO4FaUDBCRRmPMkCTbN2ObDW10ChfuNsaMEJF9wFhjTLuz\nfZcxZqSI1AN18SUnnBLqi50mNYjIV4GwMeY7/l+ZovSOWhaKkj1MiveZEF+vqAONKyoFgoqFomSP\ny+KWy5z3L2CrnwJ8HFvUEGx7y3+FziZF1bkapKL0BX1qUZTMKHe6z7n82Rjjps8OE5HXsdbBFc62\nG4H7ReTfgXrgGmf7TcA9InIt1oL4V2AXilKgaMxCUbKAE7OYb4zZl++xKIofqBtKURRFSYtaFoqi\nKEpa1LJQFEVR0qJioTvlwVAAAAAgSURBVCiKoqRFxUJRFEVJi4qFoiiKkhYVC0VRFCUt/x+nG+tn\ny7zpTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read directory\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'resnet56v2_51_100'\n",
    "input_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'\n",
    "output_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/'\n",
    "json_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_21_50/model.json'\n",
    "weights_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_21_50/weights.h5'\n",
    "\n",
    "if os.path.isdir(output_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "if os.path.isdir(output_dir + str(model_name)):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir + str(model_name))\n",
    "   \n",
    "filenames = os.listdir(input_dir)\n",
    "for filename in filenames:\n",
    "    if 'image' in filename:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        print('loaded!')\n",
    "    else:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "        print('loaded!')\n",
    "\n",
    "X = np.array(X)\n",
    "X = X[:, :, :, np.newaxis]\n",
    "input_shape = X.shape[1:]\n",
    "Y = np.array(Y)\n",
    "num_classes = len(Counter(Y))\n",
    "Y = to_categorical(Y, num_classes)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=37, shuffle=True)\n",
    "print('# of images: %d' % len(X))\n",
    "print('Shape of images:', X.shape[1:])\n",
    "print('# of train set: %d' % len(X_train), '# of test set: %d' % len(X_test))\n",
    "del X, Y\n",
    "\n",
    "# Define Model\n",
    "version = 2\n",
    "n = 6\n",
    "depth = n * 9 + 2\n",
    "batch_size = 128\n",
    "epochs = 100 # 200\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "json_file = open(json_dir, 'r')\n",
    "json_model = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(json_model)\n",
    "model.load_weights(weights_dir)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n",
    "print(model_type)\n",
    "checkpoint = ModelCheckpoint(filepath=output_dir + str(model_name) + '/checkpoint.{epoch:03d}.hg',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=2,\n",
    "                             save_best_only=True)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "fit = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=callbacks, validation_split=0.2, initial_epoch=50)\n",
    "eva = model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "\n",
    "def plot_loss(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_loss = plt\n",
    "    plt_loss.plot(history.history['loss'])\n",
    "    plt_loss.plot(history.history['val_loss'])\n",
    "    plt_loss.title('Model Loss')\n",
    "    plt_loss.xlabel('Epoch')\n",
    "    plt_loss.ylabel('Loss')\n",
    "    plt_loss.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/loss.png'\n",
    "    plt_loss.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def plot_acc(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_acc = plt\n",
    "    plt_acc.plot(history.history['acc'])\n",
    "    plt_acc.plot(history.history['val_acc'])\n",
    "    plt_acc.title('Model Accuracy')\n",
    "    plt_acc.xlabel('Epoch')\n",
    "    plt_acc.ylabel('Accuracy')\n",
    "    plt_acc.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/accuracy.png'\n",
    "    plt_acc.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def csv_fit(history, output_dir, model_name):\n",
    "    train_data = pd.DataFrame(history.history)\n",
    "    train_data.to_csv(output_dir + str(model_name) + '/csv_fit.csv')\n",
    "    return None\n",
    "\n",
    "\n",
    "def csv_eva(history, output_dir, model_name):\n",
    "    test_data = pd.DataFrame(history)\n",
    "    test_data = test_data.T\n",
    "    if len(history) == 5:\n",
    "        test_data_header = ['test_loss', 'test_acc', 'precision', 'recall', 'f1score']\n",
    "    else:\n",
    "        test_data_header = ['test_loss', 'test_acc']\n",
    "    test_data.to_csv(output_dir + str(model_name) + '/csv_eva.csv', header=test_data_header)\n",
    "    return None\n",
    "\n",
    "\n",
    "print('Model: ', model_name, ', Loss: ', eva[0], ', Accuracy: ', eva[1])\n",
    "plot_loss(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "plot_acc(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_fit(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_eva(history=eva, output_dir=output_dir, model_name=model_name)\n",
    "model.save(output_dir + str(model_name) + '/model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(output_dir + str(model_name) + '/model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "model_yaml = model.to_yaml()\n",
    "with open(output_dir + str(model_name) + '/model.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    yaml_file.close()\n",
    "model.save_weights(output_dir + str(model_name) + '/weights.h5')\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P03jIzPmZt7x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print('=====output=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_2/resnet56v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tlTPcCPG-lDX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COLAB_1_ResNet_51_100.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "1HdIYR8Sf10if8VmuF34CNP5ArUQJ0-Zs",
     "timestamp": 1.560534966683E12
    },
    {
     "file_id": "1A6BwnddGlmqiw9_7RNdf3lbwQhlJVGGw",
     "timestamp": 1.560508194285E12
    },
    {
     "file_id": "1iae9TyBzO1_n98a9eM4PRFBMSk7Obqg0",
     "timestamp": 1.560497983028E12
    },
    {
     "file_id": "1YFhVY6ZVnKuvtjN7A8vFhi_Gq-wuHNO5",
     "timestamp": 1.560493355521E12
    },
    {
     "file_id": "1oUBaAuby6umdZMtWxu5UTCkCihieEzko",
     "timestamp": 1.560479353623E12
    },
    {
     "file_id": "1OkE8SHoHTgYWYBgfaFvcyFHZyUhN4zOJ",
     "timestamp": 1.560308126915E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
