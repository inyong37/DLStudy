{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d3WhoYlxxc67",
    "colab_type": "code",
    "outputId": "075dd3cd-151e-4037-9921-b80e07d24d75",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560565727325E12,
     "user_tz": -540.0,
     "elapsed": 59067.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Inyong Hwang (lkan6004@gmail.com)\n",
    "# Date: 2019-06-15-Sat\n",
    "# Korean Character STR 64*64 by ResNet epoch=101~150 \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SdC6ExhCxkKN",
    "colab_type": "code",
    "outputId": "9408d16c-5ad0-43e5-b7b8-b1c886014762",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560565744991E12,
     "user_tz": -540.0,
     "elapsed": 4249.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Google Drive=====\n",
      " 논문\t\t\t      'Colab Notebooks'   Lab-Desktop   PUBLIC\n",
      "'AI 사물인식 해커톤 (2).zip'   Dataset\t\t  Program       USB\n",
      "=====input=====\n",
      "images.pkl  labels.pkl\n"
     ]
    }
   ],
   "source": [
    "print('=====Google Drive=====')\n",
    "!ls '/content/drive/My Drive/'\n",
    "print('=====input=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zajE3nISxsQA",
    "colab_type": "code",
    "outputId": "fb2de392-44ca-421e-b43b-cb8867d1917c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560585486953E12,
     "user_tz": -540.0,
     "elapsed": 1.9698657E7,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12699.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels.pkl\n",
      "loaded!\n",
      "loading images.pkl\n",
      "loaded!\n",
      "# of images: 139104\n",
      "Shape of images: (64, 64, 1)\n",
      "# of train set: 111283 # of test set: 27821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0615 02:30:14.407130 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0615 02:30:14.501810 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0615 02:30:14.555964 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0615 02:30:14.556843 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0615 02:30:14.557633 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0615 02:30:17.516243 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0615 02:30:22.391755 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0615 02:30:28.493376 140066307094400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Image (InputLayer)        (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   160         Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 16)   1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 16)   1040        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 16)   2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   1088        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   1040        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   1088        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 16)   1040        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 16)   2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 16)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   1088        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   4160        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 128)  8320        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 128)  8320        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 128)  0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   8256        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  8320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   8256        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 128)  8320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 128)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 64)   8256        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 128)  8320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 64)   8256        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 128)  8320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 64)   8256        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 128)  8320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 128)  16512       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 128)  147584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 128)  512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 256)  33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 256)  33024       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 256)  0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  32896       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 128)  512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 256)  33024       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 256)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 256)  1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 128)  32896       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 128)  147584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 256)  33024       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 256)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 256)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 128)  32896       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 128)  147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 128)  512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 256)  33024       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 256)  0           add_15[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 256)  1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 256)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 128)  32896       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 256)  33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 256)  0           add_16[0][0]                     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 256)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 128)  32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 128)  147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 128)  512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 256)  33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 256)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 2, 256)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1008)         1033200     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,704,080\n",
      "Trainable params: 2,693,680\n",
      "Non-trainable params: 10,400\n",
      "__________________________________________________________________________________________________\n",
      "Learning rate:  0.001\n",
      "ResNet56v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 02:30:29.335467 140066307094400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89026 samples, validate on 22257 samples\n",
      "Epoch 101/150\n",
      "Learning rate:  0.0001\n",
      " - 405s - loss: 0.0074 - acc: 0.9998 - val_loss: 0.0415 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00101: val_acc improved from -inf to 0.99358, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.101.hg\n",
      "Epoch 102/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0071 - acc: 0.9998 - val_loss: 0.0361 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.99358 to 0.99411, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.102.hg\n",
      "Epoch 103/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0070 - acc: 0.9998 - val_loss: 0.0345 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.99411 to 0.99447, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.103.hg\n",
      "Epoch 104/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0066 - acc: 0.9998 - val_loss: 0.0363 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.99447 to 0.99506, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.104.hg\n",
      "Epoch 105/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0067 - acc: 0.9998 - val_loss: 0.0344 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.99506\n",
      "Epoch 106/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0062 - acc: 0.9999 - val_loss: 0.0339 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.99506\n",
      "Epoch 107/150\n",
      "Learning rate:  0.0001\n",
      " - 390s - loss: 0.0060 - acc: 0.9999 - val_loss: 0.0339 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.99506 to 0.99510, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.107.hg\n",
      "Epoch 108/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0063 - acc: 0.9997 - val_loss: 0.0356 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.99510\n",
      "Epoch 109/150\n",
      "Learning rate:  0.0001\n",
      " - 392s - loss: 0.0060 - acc: 0.9999 - val_loss: 0.0315 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.99510 to 0.99519, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.109.hg\n",
      "Epoch 110/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0056 - acc: 0.9999 - val_loss: 0.0325 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.99519 to 0.99528, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.110.hg\n",
      "Epoch 111/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0055 - acc: 0.9999 - val_loss: 0.0335 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.99528\n",
      "Epoch 112/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0055 - acc: 0.9998 - val_loss: 0.0357 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.99528\n",
      "Epoch 113/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0064 - acc: 0.9996 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.99528\n",
      "Epoch 114/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.99528\n",
      "Epoch 115/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0051 - acc: 0.9999 - val_loss: 0.0355 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.99528\n",
      "Epoch 116/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0050 - acc: 0.9999 - val_loss: 0.0336 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.99528\n",
      "Epoch 117/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0059 - acc: 0.9997 - val_loss: 0.0497 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.99528\n",
      "Epoch 118/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0055 - acc: 0.9998 - val_loss: 0.0337 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.99528\n",
      "Epoch 119/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0049 - acc: 0.9999 - val_loss: 0.0342 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.99528\n",
      "Epoch 120/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.99528\n",
      "Epoch 121/150\n",
      "Learning rate:  0.0001\n",
      " - 391s - loss: 0.0055 - acc: 0.9997 - val_loss: 0.0422 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.99528\n",
      "Epoch 122/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0051 - acc: 0.9999 - val_loss: 0.0365 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.99528\n",
      "Epoch 123/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.99528\n",
      "Epoch 124/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.99528\n",
      "Epoch 125/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.99528\n",
      "Epoch 126/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.99528\n",
      "Epoch 127/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.99528\n",
      "Epoch 128/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.99528\n",
      "Epoch 129/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.99528\n",
      "Epoch 130/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.99528\n",
      "Epoch 131/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.99528 to 0.99533, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.131.hg\n",
      "Epoch 132/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.99533\n",
      "Epoch 133/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.99533 to 0.99537, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.133.hg\n",
      "Epoch 134/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.99537 to 0.99542, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.134.hg\n",
      "Epoch 135/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.99542 to 0.99560, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_101_150/checkpoint.135.hg\n",
      "Epoch 136/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.99560\n",
      "Epoch 137/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.99560\n",
      "Epoch 138/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.99560\n",
      "Epoch 139/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.99560\n",
      "Epoch 140/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.99560\n",
      "Epoch 141/150\n",
      "Learning rate:  1e-05\n",
      " - 391s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.99560\n",
      "Epoch 142/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.99560\n",
      "Epoch 143/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.99560\n",
      "Epoch 144/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.99560\n",
      "Epoch 145/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.99560\n",
      "Epoch 146/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.99560\n",
      "Epoch 147/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.99560\n",
      "Epoch 148/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.99560\n",
      "Epoch 149/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.99560\n",
      "Epoch 150/150\n",
      "Learning rate:  1e-05\n",
      " - 390s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0352 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.99560\n",
      "Model:  resnet56v2_101_150 , Loss:  0.040214985684901734 , Accuracy:  0.994284892706948\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMHvB09MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read directory\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'resnet56v2_101_150'\n",
    "input_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'\n",
    "output_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/'\n",
    "json_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/model.json'\n",
    "weights_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_51_100/weights.h5'\n",
    "\n",
    "if os.path.isdir(output_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "if os.path.isdir(output_dir + str(model_name)):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir + str(model_name))\n",
    "   \n",
    "filenames = os.listdir(input_dir)\n",
    "for filename in filenames:\n",
    "    if 'image' in filename:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        print('loaded!')\n",
    "    else:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "        print('loaded!')\n",
    "\n",
    "X = np.array(X)\n",
    "X = X[:, :, :, np.newaxis]\n",
    "input_shape = X.shape[1:]\n",
    "Y = np.array(Y)\n",
    "num_classes = len(Counter(Y))\n",
    "Y = to_categorical(Y, num_classes)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=37, shuffle=True)\n",
    "print('# of images: %d' % len(X))\n",
    "print('Shape of images:', X.shape[1:])\n",
    "print('# of train set: %d' % len(X_train), '# of test set: %d' % len(X_test))\n",
    "del X, Y\n",
    "\n",
    "# Define \n",
    "\n",
    "version = 2\n",
    "n = 6\n",
    "depth = n * 9 + 2\n",
    "batch_size = 128\n",
    "epochs = 150 # 200\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "json_file = open(json_dir, 'r')\n",
    "json_model = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(json_model)\n",
    "model.load_weights(weights_dir)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n",
    "print(model_type)\n",
    "checkpoint = ModelCheckpoint(filepath=output_dir + str(model_name) + '/checkpoint.{epoch:03d}.hg',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=2,\n",
    "                             save_best_only=True)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "fit = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=callbacks, validation_split=0.2, initial_epoch=100)\n",
    "eva = model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "\n",
    "def plot_loss(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_loss = plt\n",
    "    plt_loss.plot(history.history['loss'])\n",
    "    plt_loss.plot(history.history['val_loss'])\n",
    "    plt_loss.title('Model Loss')\n",
    "    plt_loss.xlabel('Epoch')\n",
    "    plt_loss.ylabel('Loss')\n",
    "    plt_loss.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/loss.png'\n",
    "    plt_loss.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def plot_acc(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_acc = plt\n",
    "    plt_acc.plot(history.history['acc'])\n",
    "    plt_acc.plot(history.history['val_acc'])\n",
    "    plt_acc.title('Model Accuracy')\n",
    "    plt_acc.xlabel('Epoch')\n",
    "    plt_acc.ylabel('Accuracy')\n",
    "    plt_acc.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/accuracy.png'\n",
    "    plt_acc.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def csv_fit(history, output_dir, model_name):\n",
    "    train_data = pd.DataFrame(history.history)\n",
    "    train_data.to_csv(output_dir + str(model_name) + '/csv_fit.csv')\n",
    "    return None\n",
    "\n",
    "\n",
    "def csv_eva(history, output_dir, model_name):\n",
    "    test_data = pd.DataFrame(history)\n",
    "    test_data = test_data.T\n",
    "    if len(history) == 5:\n",
    "        test_data_header = ['test_loss', 'test_acc', 'precision', 'recall', 'f1score']\n",
    "    else:\n",
    "        test_data_header = ['test_loss', 'test_acc']\n",
    "    test_data.to_csv(output_dir + str(model_name) + '/csv_eva.csv', header=test_data_header)\n",
    "    return None\n",
    "\n",
    "\n",
    "print('Model: ', model_name, ', Loss: ', eva[0], ', Accuracy: ', eva[1])\n",
    "plot_loss(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "plot_acc(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_fit(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_eva(history=eva, output_dir=output_dir, model_name=model_name)\n",
    "model.save(output_dir + str(model_name) + '/model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(output_dir + str(model_name) + '/model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "model_yaml = model.to_yaml()\n",
    "with open(output_dir + str(model_name) + '/model.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    yaml_file.close()\n",
    "model.save_weights(output_dir + str(model_name) + '/weights.h5')\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P03jIzPmZt7x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print('=====output=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_2/resnet56v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tlTPcCPG-lDX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COLAB_1_ResNet_101_150.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "1Oznv-mZazv25aXZjXV6vfb0xphxR2C7o",
     "timestamp": 1.560564439854E12
    },
    {
     "file_id": "1HdIYR8Sf10if8VmuF34CNP5ArUQJ0-Zs",
     "timestamp": 1.560534966683E12
    },
    {
     "file_id": "1A6BwnddGlmqiw9_7RNdf3lbwQhlJVGGw",
     "timestamp": 1.560508194285E12
    },
    {
     "file_id": "1iae9TyBzO1_n98a9eM4PRFBMSk7Obqg0",
     "timestamp": 1.560497983028E12
    },
    {
     "file_id": "1YFhVY6ZVnKuvtjN7A8vFhi_Gq-wuHNO5",
     "timestamp": 1.560493355521E12
    },
    {
     "file_id": "1oUBaAuby6umdZMtWxu5UTCkCihieEzko",
     "timestamp": 1.560479353623E12
    },
    {
     "file_id": "1OkE8SHoHTgYWYBgfaFvcyFHZyUhN4zOJ",
     "timestamp": 1.560308126915E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
