{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "d3WhoYlxxc67",
    "colab_type": "code",
    "outputId": "561497b6-f55a-4c7c-994d-16c18e9dbea1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560508366248E12,
     "user_tz": -540.0,
     "elapsed": 35850.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Inyong Hwang (lkan6004@gmail.com)\n",
    "# Date: 2019-06-15-Sat\n",
    "# Korean Character STR 64*64 by ResNet epoch=21~50\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SdC6ExhCxkKN",
    "colab_type": "code",
    "outputId": "7d77593f-1a73-4cc2-8e62-1e3625f53949",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.56050837584E12,
     "user_tz": -540.0,
     "elapsed": 6737.0,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Google Drive=====\n",
      " 논문\t\t\t      'Colab Notebooks'   Lab-Desktop   PUBLIC\n",
      "'AI 사물인식 해커톤 (2).zip'   Dataset\t\t  Program       USB\n",
      "=====input=====\n",
      "images.pkl  labels.pkl\n"
     ]
    }
   ],
   "source": [
    "print('=====Google Drive=====')\n",
    "!ls '/content/drive/My Drive/'\n",
    "print('=====input=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zajE3nISxsQA",
    "colab_type": "code",
    "outputId": "6e5d2129-baa9-4bda-8079-d78b70e5e182",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.560532730583E12,
     "user_tz": -540.0,
     "elapsed": 2.186449E7,
     "user": {
      "displayName": "L Kan",
      "photoUrl": "",
      "userId": "05643648821851919258"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10899.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels.pkl\n",
      "loaded!\n",
      "loading images.pkl\n",
      "loaded!\n",
      "# of images: 139104\n",
      "Shape of images: (64, 64, 1)\n",
      "# of train set: 111283 # of test set: 27821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0614 10:33:29.495330 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0614 10:33:29.595162 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0614 10:33:29.655704 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0614 10:33:29.657053 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0614 10:33:29.661114 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0614 10:33:32.710068 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0614 10:33:39.059105 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0614 10:33:43.385267 140640444643200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Image (InputLayer)        (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   160         Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 16)   1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 16)   1040        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 16)   2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   1088        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   1040        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   1088        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 16)   1040        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 16)   2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 16)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   1088        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   4160        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 128)  8320        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 128)  8320        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 128)  0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   8256        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  8320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   8256        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 128)  8320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 128)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 64)   8256        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 128)  8320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 64)   8256        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 128)  8320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 64)   8256        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 128)  8320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 128)  16512       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 128)  147584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 128)  512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 256)  33024       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 256)  33024       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 256)  0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  32896       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 128)  512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 256)  33024       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 256)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 256)  1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 128)  32896       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 128)  147584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 256)  33024       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 256)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 256)  1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 256)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 128)  32896       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 128)  147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 128)  512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 256)  33024       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 256)  0           add_15[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 256)  1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 256)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 128)  32896       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 128)  512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 256)  33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 256)  0           add_16[0][0]                     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 256)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 128)  32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 128)  147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 128)  512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 256)  33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 256)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 2, 256)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1008)         1033200     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,704,080\n",
      "Trainable params: 2,693,680\n",
      "Non-trainable params: 10,400\n",
      "__________________________________________________________________________________________________\n",
      "Learning rate:  0.001\n",
      "ResNet56v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0614 10:33:44.519177 140640444643200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89026 samples, validate on 22257 samples\n",
      "Epoch 21/50\n",
      "Learning rate:  0.001\n",
      " - 825s - loss: 0.1080 - acc: 0.9915 - val_loss: 0.1442 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00021: val_acc improved from -inf to 0.98284, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_21_50/checkpoint.021.hg\n",
      "Epoch 22/50\n",
      "Learning rate:  0.001\n",
      " - 808s - loss: 0.0988 - acc: 0.9928 - val_loss: 0.2025 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98284\n",
      "Epoch 23/50\n",
      "Learning rate:  0.001\n",
      " - 807s - loss: 0.0942 - acc: 0.9938 - val_loss: 0.1846 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98284\n",
      "Epoch 24/50\n",
      "Learning rate:  0.001\n",
      " - 808s - loss: 0.0912 - acc: 0.9936 - val_loss: 0.2011 - val_acc: 0.9643\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98284\n",
      "Epoch 25/50\n",
      "Learning rate:  0.001\n",
      " - 806s - loss: 0.0919 - acc: 0.9928 - val_loss: 0.1295 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.98284 to 0.98351, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_21_50/checkpoint.025.hg\n",
      "Epoch 26/50\n",
      "Learning rate:  0.001\n",
      " - 809s - loss: 0.0833 - acc: 0.9945 - val_loss: 0.7129 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98351\n",
      "Epoch 27/50\n",
      "Learning rate:  0.001\n",
      " - 810s - loss: 0.0805 - acc: 0.9947 - val_loss: 0.0974 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.98351 to 0.99074, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_21_50/checkpoint.027.hg\n",
      "Epoch 28/50\n",
      "Learning rate:  0.001\n",
      " - 813s - loss: 0.0820 - acc: 0.9941 - val_loss: 0.2745 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99074\n",
      "Epoch 29/50\n",
      "Learning rate:  0.001\n",
      " - 813s - loss: 0.0798 - acc: 0.9942 - val_loss: 0.1037 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99074\n",
      "Epoch 30/50\n",
      "Learning rate:  0.001\n",
      " - 814s - loss: 0.0741 - acc: 0.9950 - val_loss: 0.1036 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99074\n",
      "Epoch 31/50\n",
      "Learning rate:  0.001\n",
      " - 812s - loss: 0.0763 - acc: 0.9945 - val_loss: 0.1156 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99074\n",
      "Epoch 32/50\n",
      "Learning rate:  0.001\n",
      " - 809s - loss: 0.0686 - acc: 0.9958 - val_loss: 10.1334 - val_acc: 0.1672\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99074\n",
      "Epoch 33/50\n",
      "Learning rate:  0.001\n",
      " - 810s - loss: 0.0689 - acc: 0.9955 - val_loss: 0.4148 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99074\n",
      "Epoch 34/50\n",
      "Learning rate:  0.001\n",
      " - 812s - loss: 0.0708 - acc: 0.9944 - val_loss: 0.2195 - val_acc: 0.9653\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99074\n",
      "Epoch 35/50\n",
      "Learning rate:  0.001\n",
      " - 814s - loss: 0.0660 - acc: 0.9957 - val_loss: 1.0385 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99074\n",
      "Epoch 36/50\n",
      "Learning rate:  0.001\n",
      " - 814s - loss: 0.0657 - acc: 0.9950 - val_loss: 0.3271 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99074\n",
      "Epoch 37/50\n",
      "Learning rate:  0.001\n",
      " - 811s - loss: 0.0654 - acc: 0.9958 - val_loss: 0.1193 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99074\n",
      "Epoch 38/50\n",
      "Learning rate:  0.001\n",
      " - 806s - loss: 0.0592 - acc: 0.9959 - val_loss: 0.1798 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99074\n",
      "Epoch 39/50\n",
      "Learning rate:  0.001\n",
      " - 803s - loss: 0.0618 - acc: 0.9954 - val_loss: 0.1078 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99074\n",
      "Epoch 40/50\n",
      "Learning rate:  0.001\n",
      " - 800s - loss: 0.0609 - acc: 0.9956 - val_loss: 0.1227 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99074\n",
      "Epoch 41/50\n",
      "Learning rate:  0.001\n",
      " - 799s - loss: 0.0578 - acc: 0.9960 - val_loss: 0.1550 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99074\n",
      "Epoch 42/50\n",
      "Learning rate:  0.001\n",
      " - 797s - loss: 0.0596 - acc: 0.9954 - val_loss: 0.1095 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99074\n",
      "Epoch 43/50\n",
      "Learning rate:  0.001\n",
      " - 797s - loss: 0.0560 - acc: 0.9962 - val_loss: 0.1097 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99074\n",
      "Epoch 44/50\n",
      "Learning rate:  0.001\n",
      " - 797s - loss: 0.0517 - acc: 0.9970 - val_loss: 0.0702 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.99074 to 0.99277, saving model to /content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_21_50/checkpoint.044.hg\n",
      "Epoch 45/50\n",
      "Learning rate:  0.001\n",
      " - 797s - loss: 0.0547 - acc: 0.9958 - val_loss: 0.0913 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99277\n",
      "Epoch 46/50\n",
      "Learning rate:  0.001\n",
      " - 796s - loss: 0.0553 - acc: 0.9959 - val_loss: 0.1687 - val_acc: 0.9663\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99277\n",
      "Epoch 47/50\n",
      "Learning rate:  0.001\n",
      " - 796s - loss: 0.0542 - acc: 0.9957 - val_loss: 0.1707 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99277\n",
      "Epoch 48/50\n",
      "Learning rate:  0.001\n",
      " - 796s - loss: 0.0487 - acc: 0.9973 - val_loss: 0.1716 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99277\n",
      "Epoch 49/50\n",
      "Learning rate:  0.001\n",
      " - 796s - loss: 0.0500 - acc: 0.9961 - val_loss: 0.1350 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99277\n",
      "Epoch 50/50\n",
      "Learning rate:  0.001\n",
      " - 795s - loss: 0.0515 - acc: 0.9961 - val_loss: 0.1000 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99277\n",
      "Model:  resnet56v2_21_50 , Loss:  0.10701769742798567 , Accuracy:  0.9833578951152008\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read directory\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_name = 'resnet56v2_21_50'\n",
    "input_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_64v4/'\n",
    "output_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/'\n",
    "json_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_11_20/model.json'\n",
    "weights_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_5/resnet56v2_11_20/weights.h5'\n",
    "\n",
    "if os.path.isdir(output_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "if os.path.isdir(output_dir + str(model_name)):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(output_dir + str(model_name))\n",
    "   \n",
    "filenames = os.listdir(input_dir)\n",
    "for filename in filenames:\n",
    "    if 'image' in filename:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        print('loaded!')\n",
    "    else:\n",
    "        print('loading %s' % filename)\n",
    "        with open(input_dir + filename, 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "        print('loaded!')\n",
    "\n",
    "X = np.array(X)\n",
    "X = X[:, :, :, np.newaxis]\n",
    "input_shape = X.shape[1:]\n",
    "Y = np.array(Y)\n",
    "num_classes = len(Counter(Y))\n",
    "Y = to_categorical(Y, num_classes)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=37, shuffle=True)\n",
    "print('# of images: %d' % len(X))\n",
    "print('Shape of images:', X.shape[1:])\n",
    "print('# of train set: %d' % len(X_train), '# of test set: %d' % len(X_test))\n",
    "del X, Y\n",
    "\n",
    "# Define Model\n",
    "version = 2\n",
    "n = 6\n",
    "depth = n * 9 + 2\n",
    "batch_size = 128\n",
    "epochs = 50 # 200\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "json_file = open(json_dir, 'r')\n",
    "json_model = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(json_model)\n",
    "model.load_weights(weights_dir)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n",
    "print(model_type)\n",
    "checkpoint = ModelCheckpoint(filepath=output_dir + str(model_name) + '/checkpoint.{epoch:03d}.hg',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=2,\n",
    "                             save_best_only=True)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "fit = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=callbacks, validation_split=0.2, initial_epoch=20)\n",
    "eva = model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "\n",
    "def plot_loss(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_loss = plt\n",
    "    plt_loss.plot(history.history['loss'])\n",
    "    plt_loss.plot(history.history['val_loss'])\n",
    "    plt_loss.title('Model Loss')\n",
    "    plt_loss.xlabel('Epoch')\n",
    "    plt_loss.ylabel('Loss')\n",
    "    plt_loss.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/loss.png'\n",
    "    plt_loss.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def plot_acc(history, output_dir, model_name):\n",
    "    plt.clf()\n",
    "    plt_acc = plt\n",
    "    plt_acc.plot(history.history['acc'])\n",
    "    plt_acc.plot(history.history['val_acc'])\n",
    "    plt_acc.title('Model Accuracy')\n",
    "    plt_acc.xlabel('Epoch')\n",
    "    plt_acc.ylabel('Accuracy')\n",
    "    plt_acc.legend(['Train', 'Test'], loc=0)\n",
    "    figure = output_dir + str(model_name) + '/accuracy.png'\n",
    "    plt_acc.savefig(figure, dpi=1080)\n",
    "\n",
    "\n",
    "def csv_fit(history, output_dir, model_name):\n",
    "    train_data = pd.DataFrame(history.history)\n",
    "    train_data.to_csv(output_dir + str(model_name) + '/csv_fit.csv')\n",
    "    return None\n",
    "\n",
    "\n",
    "def csv_eva(history, output_dir, model_name):\n",
    "    test_data = pd.DataFrame(history)\n",
    "    test_data = test_data.T\n",
    "    if len(history) == 5:\n",
    "        test_data_header = ['test_loss', 'test_acc', 'precision', 'recall', 'f1score']\n",
    "    else:\n",
    "        test_data_header = ['test_loss', 'test_acc']\n",
    "    test_data.to_csv(output_dir + str(model_name) + '/csv_eva.csv', header=test_data_header)\n",
    "    return None\n",
    "\n",
    "\n",
    "print('Model: ', model_name, ', Loss: ', eva[0], ', Accuracy: ', eva[1])\n",
    "plot_loss(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "plot_acc(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_fit(history=fit, output_dir=output_dir, model_name=model_name)\n",
    "csv_eva(history=eva, output_dir=output_dir, model_name=model_name)\n",
    "model.save(output_dir + str(model_name) + '/model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(output_dir + str(model_name) + '/model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "model_yaml = model.to_yaml()\n",
    "with open(output_dir + str(model_name) + '/model.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    yaml_file.close()\n",
    "model.save_weights(output_dir + str(model_name) + '/weights.h5')\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P03jIzPmZt7x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print('=====output=====')\n",
    "!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_2/resnet56v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tlTPcCPG-lDX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COLAB_1_ResNet_21_50.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "1A6BwnddGlmqiw9_7RNdf3lbwQhlJVGGw",
     "timestamp": 1.560508194285E12
    },
    {
     "file_id": "1iae9TyBzO1_n98a9eM4PRFBMSk7Obqg0",
     "timestamp": 1.560497983028E12
    },
    {
     "file_id": "1YFhVY6ZVnKuvtjN7A8vFhi_Gq-wuHNO5",
     "timestamp": 1.560493355521E12
    },
    {
     "file_id": "1oUBaAuby6umdZMtWxu5UTCkCihieEzko",
     "timestamp": 1.560479353623E12
    },
    {
     "file_id": "1OkE8SHoHTgYWYBgfaFvcyFHZyUhN4zOJ",
     "timestamp": 1.560308126915E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
