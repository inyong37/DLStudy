{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"COLAB_2_ResNet_1_100_128_X.ipynb","version":"0.3.2","provenance":[{"file_id":"1gGd0MkWgiM4YJEpHzUv-vp7QP24POALT","timestamp":1562652792896},{"file_id":"1vY3ME9i45zPbLGtP2r9XCDST--n0BkAP","timestamp":1560748429988},{"file_id":"1iae9TyBzO1_n98a9eM4PRFBMSk7Obqg0","timestamp":1560693183518},{"file_id":"1YFhVY6ZVnKuvtjN7A8vFhi_Gq-wuHNO5","timestamp":1560493355521},{"file_id":"1oUBaAuby6umdZMtWxu5UTCkCihieEzko","timestamp":1560479353623},{"file_id":"1OkE8SHoHTgYWYBgfaFvcyFHZyUhN4zOJ","timestamp":1560308126915}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"d3WhoYlxxc67","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","# Author: Inyong Hwang (inyong1020@gmail.com)\n","# Date: 2019-07-09-Tue\n","# Korean Character STR 128*128 by ResNet epoch=1~100\n","# Memory Error\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdC6ExhCxkKN","colab_type":"code","colab":{}},"source":["print('=====Google Drive=====')\n","!ls '/content/drive/My Drive/'\n","print('=====input=====')\n","!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_128v4/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zajE3nISxsQA","colab_type":"code","colab":{}},"source":["# read directory\n","import sys\n","import os\n","import pickle\n","import numpy as np\n","from keras.utils import to_categorical\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from keras import layers\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from keras.layers import AveragePooling2D, Input, Flatten\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.regularizers import l2\n","from keras.models import Model\n","from keras import backend as k\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","model_name = 'resnet56v2_1_100_128'\n","input_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/PKL_128v4/'\n","output_dir = '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_6/'\n","\n","if os.path.isdir(output_dir):\n","    pass\n","else:\n","    os.mkdir(output_dir)\n","\n","if os.path.isdir(output_dir + str(model_name)):\n","    pass\n","else:\n","    os.mkdir(output_dir + str(model_name))\n","   \n","filenames = os.listdir(input_dir)\n","for filename in filenames:\n","    if 'image' in filename:\n","        print('loading %s' % filename)\n","        with open(input_dir + filename, 'rb') as f:\n","            X = pickle.load(f)\n","        print('loaded!')\n","    else:\n","        print('loading %s' % filename)\n","        with open(input_dir + filename, 'rb') as f:\n","            Y = pickle.load(f)\n","        print('loaded!')\n","\n","X = np.array(X)\n","X = X[:, :, :, np.newaxis]\n","input_shape = X.shape[1:]\n","Y = np.array(Y)\n","num_classes = len(Counter(Y))\n","Y = to_categorical(Y, num_classes)\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=37, shuffle=True)\n","print('# of images: %d' % len(X))\n","print('Shape of images:', X.shape[1:])\n","print('# of train set: %d' % len(X_train), '# of test set: %d' % len(X_test))\n","del X, Y\n","\n","# Define Model\n","version = 2\n","n = 6\n","depth = n * 9 + 2\n","batch_size = 64 # 128\n","epochs = 100 # 200\n","model_type = 'ResNet%dv%d' % (depth, version)\n","\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr\n","\n","\n","def resnet_layer(inputs,\n","                 filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","    conv = Conv2D(filters=filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","\n","def resnet_v2(input_shape=input_shape, depth=depth, classes=num_classes):\n","    filters_in = 16\n","    resnet_blocks = int((depth - 2) / 9)\n","\n","    i = Input(shape=input_shape, name='Input_Image')\n","    x = resnet_layer(inputs=i, filters=filters_in, conv_first=True)\n","    for stage in range(3):\n","        for resnet_block in range(resnet_blocks):\n","            activation = 'relu'\n","            batch_normalization = True\n","            strides = 1\n","            if stage == 0:\n","                filters_out = filters_in * 4\n","                if resnet_block == 0:\n","                    activation = None\n","                    batch_normalization = False\n","            else:\n","                filters_out = filters_in * 2\n","                if resnet_block == 0:\n","                    strides = 2\n","            y = resnet_layer(inputs=x, filters=filters_in, kernel_size=1, strides=strides, activation=activation, batch_normalization=batch_normalization, conv_first=False)\n","            y = resnet_layer(inputs=y, filters=filters_in, conv_first=False)\n","            y = resnet_layer(inputs=y, filters=filters_out, kernel_size=1, conv_first=False)\n","            if resnet_block == 0:\n","                x = resnet_layer(inputs=x, filters=filters_out, kernel_size=1, strides=strides, activation=None, batch_normalization=False)\n","            x = layers.add([x, y])\n","        filters_in = filters_out\n","\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    # x = AveragePooling2D(pool_size=8)(x)\n","    x = Flatten()(x)\n","    y = Dense(classes, activation='softmax', kernel_initializer='he_normal')(x)\n","    model = Model(inputs=i, outputs=y)\n","    return model\n","\n","\n","model = resnet_v2(input_shape=input_shape, depth=depth)\n","model.summary()\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n","print(model_type)\n","checkpoint = ModelCheckpoint(filepath=output_dir + str(model_name) + '/checkpoint.{epoch:03d}.hg',\n","                             monitor='val_acc',\n","                             verbose=2,\n","                             save_best_only=True)\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\n","fit = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=callbacks, validation_split=0.2, initial_epoch=0)\n","eva = model.evaluate(X_test, Y_test, verbose=2)\n","\n","\n","def plot_loss(history, output_dir, model_name):\n","    plt.clf()\n","    plt_loss = plt\n","    plt_loss.plot(history.history['loss'])\n","    plt_loss.plot(history.history['val_loss'])\n","    plt_loss.title('Model Loss')\n","    plt_loss.xlabel('Epoch')\n","    plt_loss.ylabel('Loss')\n","    plt_loss.legend(['Train', 'Test'], loc=0)\n","    figure = output_dir + str(model_name) + '/loss.png'\n","    plt_loss.savefig(figure, dpi=1080)\n","\n","\n","def plot_acc(history, output_dir, model_name):\n","    plt.clf()\n","    plt_acc = plt\n","    plt_acc.plot(history.history['acc'])\n","    plt_acc.plot(history.history['val_acc'])\n","    plt_acc.title('Model Accuracy')\n","    plt_acc.xlabel('Epoch')\n","    plt_acc.ylabel('Accuracy')\n","    plt_acc.legend(['Train', 'Test'], loc=0)\n","    figure = output_dir + str(model_name) + '/accuracy.png'\n","    plt_acc.savefig(figure, dpi=1080)\n","\n","\n","def csv_fit(history, output_dir, model_name):\n","    train_data = pd.DataFrame(history.history)\n","    train_data.to_csv(output_dir + str(model_name) + '/csv_fit.csv')\n","    return None\n","\n","\n","def csv_eva(history, output_dir, model_name):\n","    test_data = pd.DataFrame(history)\n","    test_data = test_data.T\n","    if len(history) == 5:\n","        test_data_header = ['test_loss', 'test_acc', 'precision', 'recall', 'f1score']\n","    else:\n","        test_data_header = ['test_loss', 'test_acc']\n","    test_data.to_csv(output_dir + str(model_name) + '/csv_eva.csv', header=test_data_header)\n","    return None\n","\n","\n","print('Model: ', model_name, ', Loss: ', eva[0], ', Accuracy: ', eva[1])\n","plot_loss(history=fit, output_dir=output_dir, model_name=model_name)\n","plot_acc(history=fit, output_dir=output_dir, model_name=model_name)\n","csv_fit(history=fit, output_dir=output_dir, model_name=model_name)\n","csv_eva(history=eva, output_dir=output_dir, model_name=model_name)\n","model.save(output_dir + str(model_name) + '/model.h5')\n","model_json = model.to_json()\n","with open(output_dir + str(model_name) + '/model.json', 'w') as json_file:\n","    json_file.write(model_json)\n","    json_file.close()\n","model_yaml = model.to_yaml()\n","with open(output_dir + str(model_name) + '/model.yaml', 'w') as yaml_file:\n","    yaml_file.write(model_yaml)\n","    yaml_file.close()\n","model.save_weights(output_dir + str(model_name) + '/weights.h5')\n","print('Done!')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P03jIzPmZt7x","colab_type":"code","colab":{}},"source":["print('=====output=====')\n","!ls '/content/drive/My Drive/PUBLIC/PROJECT/OCR/STR/COLAB_OUTPUT_2/resnet56v2'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlTPcCPG-lDX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
